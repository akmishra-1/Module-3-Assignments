{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on July 6th, BUT no late points will be charged if you get it in by the last late deadline. \n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with the **UCI Adult** dataset. This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- We use `StratifiedKFold` instead of plain `KFold` so that every fold keeps the original class proportions.\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score for binary classification) instead of regression metrics.\n",
    "- We could explore misclassified instances through a confusion matrix (though we will not do that in this homework).\n",
    "\n",
    "For this assignment, you’ll build a gradient boosting classification using `HistGradientBoostingClassifier` (HGBC) and explore ways of tuning the hyperparameters, including using the technique of early stopping, which basically avoiding have to tune the number of estimators (called `max_iter` in HGBC). \n",
    "\n",
    "HGBC has many advantages, which we explain below. \n",
    "\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 7 graded problems, each worth 7 points, and you get 1 point free if you complete the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    " \n",
    "# Data source\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    " \n",
    "# scikit-learn core tools \n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    " \n",
    "# Import model \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    " \n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    " \n",
    "# Distributions for random search\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "\n",
    "# pandas dtypes helpers\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from pandas import CategoricalDtype\n",
    "\n",
    "# Optuna Hyperparameter Search tool    (may need to be installed)\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 1: Load and Preprocess the UCI Adult Income Dataset\n",
    "\n",
    "- Load the dataset from sklearn\n",
    "- Preliminary EDA\n",
    "- Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      " 14  class           48842 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load and clean\n",
    "df = fetch_openml(name='adult', version=2, as_frame=True).frame\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace=True)            # Some datasets use ? instead of Nan for missing data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: Is the dataset imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "<=50K    0.760718\n",
      ">50K     0.239282\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES:** It looks like this dataset is somewhat imbalanced. Therefore, we will \n",
    "1. Tell the model to compensate during training by setting `class_weight='balanced'` when defining the model;\n",
    "2. Evaluate it `balanced_accuracy` instead of `accuracy` and with class-aware metrics (precision, recall, F1); and\n",
    "3. [Optional] Adjust the probability threshold instead of relying on raw accuracy alone after examining the precision-recall trade-off you observe at 0.5.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Based on the considerations in **Appendix One**, we'll make the following changes to the dataset to facilitate training:\n",
    "\n",
    "\n",
    "1. Drop `fnlwgt` and `education`.   \n",
    "3. Replace `capital-gain` and `capital-loss` by their difference `capital_net` and add a log-scaled version `capital_net_log`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              48842 non-null  int64   \n",
      " 1   workclass        46043 non-null  category\n",
      " 2   education-num    48842 non-null  int64   \n",
      " 3   marital-status   48842 non-null  category\n",
      " 4   occupation       46033 non-null  category\n",
      " 5   relationship     48842 non-null  category\n",
      " 6   race             48842 non-null  category\n",
      " 7   sex              48842 non-null  category\n",
      " 8   hours-per-week   48842 non-null  int64   \n",
      " 9   native-country   47985 non-null  category\n",
      " 10  class            48842 non-null  category\n",
      " 11  capital_net      48842 non-null  int64   \n",
      " 12  capital_net_log  48842 non-null  float64 \n",
      "dtypes: category(8), float64(1), int64(4)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop the survey-weight column\n",
    "df_eng = df.drop(columns=[\"fnlwgt\"])\n",
    "\n",
    "# Keep only the ordinal education feature\n",
    "df_eng = df_eng.drop(columns=[\"education\"])      # retain 'education-num'\n",
    "\n",
    "# Combine capital gains and losses, add a log-scaled variant\n",
    "df_eng[\"capital_net\"]     = df_eng[\"capital-gain\"] - df_eng[\"capital-loss\"]\n",
    "df_eng[\"capital_net_log\"] = np.log1p(df_eng[\"capital_net\"].clip(lower=0))\n",
    "df_eng = df_eng.drop(columns=[\"capital-gain\", \"capital-loss\"])\n",
    "\n",
    "# check\n",
    "df_eng.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate target and split\n",
    "\n",
    "Create the feature set `X` and the target set `y` (using `class` as the target) and split the dataset into 80% training and 20% testing sets, making sure to stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (39073, 12) (39073,)\n",
      "Test : (9769, 12) (9769,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_eng.drop(columns=[\"class\"])\n",
    "y = (df_eng[\"class\"] == \">50K\").astype(int)\n",
    "\n",
    "# Split (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=random_seed,\n",
    "    stratify=y                           # So same proportion of classes in train and test sets\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 2: Create a data pipeline and the `HistGradientBoostingClassifier` model\n",
    "\n",
    "Histogram-based gradient boosting improves on the standard version by:\n",
    "\n",
    "* **Histogram splits:** bins each feature into ≤ `max_bins` quantiles (i.e., each bin is approximately the same size) and tests splits only between bins, slashing compute time and scaling to large data sets. Default for `max_bins` = 255. \n",
    "* **Native NaN handling:** treats missing values as their own bin—no imputation needed.\n",
    "* **Native Categorical Support**: accepts integer-encoded categories directly and tests “category c vs. all others” splits, eliminating one-hot blow-ups and fake orderings.\n",
    "* **Built-in early stopping:** stops training after no improvement in validation loss after `n_iter_no_change` rounds. `tol` defines \"improvement\" (default is 1e-7). \n",
    "* **Leaf shrinkage:** adds `l2_regularization`, which ridge-shrinks each leaf value (without changing tree shape) so tiny, noisy leaves have less effect.\n",
    "\n",
    ">**Summary:**  Histogram-based GB trades a tiny approximation error (binning) for a **huge speed-up** and adds extra conveniences, making it the preferred choice for large tabular data sets. Tuning workflow relies on **Early stopping** to stop training before overfitting occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a baseline model \n",
    "\n",
    "HGBC_model = HistGradientBoostingClassifier(\n",
    "    # tree structure and learning rate\n",
    "    learning_rate=0.1,            # These 5 parameters are at defaults for our baseline training in Problem 1             \n",
    "    max_leaf_nodes=31,            # but will be tuned by randomized search in Problem 2 and Optuna in Problem 3               \n",
    "    max_depth=None,               \n",
    "    min_samples_leaf=20,          \n",
    "    l2_regularization=0.0,        \n",
    "\n",
    "    # bins and iteration\n",
    "    max_bins=255,                 # default\n",
    "    max_iter=500,                 # high enough for early stopping\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,      # 20% monitored for early stopping\n",
    "    tol=1e-7,                     # default tolerance for validation improvement\n",
    "\n",
    "    # class imbalance\n",
    "    class_weight=\"balanced\",\n",
    "\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline appropriate for HGBC \n",
    "\n",
    "**Why use a `Pipeline` instead of encoding in the dataset first?**\n",
    "\n",
    "* **Avoid data leakage.** In each CV fold, the `OrdinalEncoder` is refit only on that fold’s training data, so the validation split never influences the encoder.\n",
    "* **Single, reusable object.** The pipeline bundles preprocessing + model, letting you call `fit`/`predict` on raw data anywhere (CV, Optuna, production) with identical behavior.\n",
    "* **Compatible with search tools.** `cross_validate`, `GridSearchCV`, and Optuna expect an estimator that can be cloned and refit; a pipeline meets that requirement automatically.\n",
    "\n",
    "Put simply, the pipeline gives you leak-free evaluation and portable, hassle-free tuning without extra code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",   # Allow unseen categories during transform\n",
    "    unknown_value=-1,                     # Code for unseen categories\n",
    "    encoded_missing_value=-2,             # Code for missing values (NaN)\n",
    "    dtype=np.int64                        # Needed for HistGradientBoostingClassifier\n",
    ")\n",
    "\n",
    "# Categorical features\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Numeric features (everything that isn’t object / category)\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"cat\", enc, cat_cols),\n",
    "     (\"num\", \"passthrough\", num_cols)]\n",
    ")\n",
    "\n",
    "pipelined_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\",   HGBC_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Baseline Cross-Validation with F1\n",
    "\n",
    "In this problem, you will run a baseline cross-validation evaluation of your `HistGradientBoostingClassifier` pipeline, using `HGBC_model` defined above. \n",
    "\n",
    "**Background:**\n",
    "\n",
    "* Since the Adult dataset is imbalanced (about 24% positives, 76% negatives), accuracy alone is not reliable.\n",
    "* We will use the **F1 score** as the evaluation metric, since it balances precision (avoiding false positives) and recall (avoiding false negatives) in a single measure. This is a fairer metric for imbalanced classification, where both types of error matter.\n",
    "* We will apply **5-fold stratified cross-validation** to make sure each fold has the same proportion of the classes as the original dataset.\n",
    "* Repeated cross-validation is optional and not required here, because the Adult dataset is large and `HistGradientBoostingClassifier` is robust to small sampling differences. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a `StratifiedKFold` cross-validation object with 5 splits, shuffling enabled, and `random_state=random_seed`.\n",
    "2. Use `cross_val_score` to estimate the mean F1 score and its standard deviation across the folds.\n",
    "3. Print out the mean and standard deviation of the F1 score, rounded to 4 decimal places.\n",
    "4. Answer the graded question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score: 0.7123\n",
      "Standard Deviation: 0.0035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "f1_scores = cross_val_score(\n",
    "    pipelined_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Mean F1 Score: {mean_f1:.4f}\")\n",
    "print(f\"Standard Deviation: {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer\n",
    "\n",
    "Set `a1` to the mean F1 score of the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a1 = mean_f1                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.7123\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a1 = {a1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Hyperparameter Optimization with Randomized Search for F1\n",
    "\n",
    "In this problem, you will tune your `pipelined_model` using `RandomizedSearchCV` to identify the best combination of tree structure and learning rate parameters that maximize the **F1 score**.\n",
    "\n",
    "**Background:**\n",
    "The F1 score is our main metric because it balances precision and recall on an imbalanced dataset. Optimizing hyperparameters for F1 ensures we manage both false positives and false negatives in a single measure.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a randomized search over the following hyperparameter ranges, using appropriate random-number distributions:\n",
    "\n",
    "   * `learning_rate` (log-uniform between 1e-3 and 0.3)\n",
    "   * `max_leaf_nodes` (integer from 16 to 256)\n",
    "   * `max_depth` (integer from 2 to 10)\n",
    "   * `min_samples_leaf` (integer from 10 to 200)\n",
    "   * `l2_regularization` (uniform between 0.0 and 2.0)\n",
    "2. Use **5-fold stratified cross-validation**, with the same settings as in Problem 1.\n",
    "3. Set `n_iter` to at least 100 trials. More trials will generally yield better results, if your time and machine allow.\n",
    "4. After running the search, show a neatly formatted table of the top 5 results, using `display(...)` showing their mean F1 scores, standard deviation, and the chosen hyperparameter values.\n",
    "5. Answer the graded question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END gb__l2_regularization=0.749080237694725, gb__learning_rate=0.22648248189516848, gb__max_depth=9, gb__max_leaf_nodes=204, gb__min_samples_leaf=30; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.749080237694725, gb__learning_rate=0.22648248189516848, gb__max_depth=9, gb__max_leaf_nodes=204, gb__min_samples_leaf=30; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.749080237694725, gb__learning_rate=0.22648248189516848, gb__max_depth=9, gb__max_leaf_nodes=204, gb__min_samples_leaf=30; total time=   0.4s\n",
      "[CV] END gb__l2_regularization=0.749080237694725, gb__learning_rate=0.22648248189516848, gb__max_depth=9, gb__max_leaf_nodes=204, gb__min_samples_leaf=30; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.749080237694725, gb__learning_rate=0.22648248189516848, gb__max_depth=9, gb__max_leaf_nodes=204, gb__min_samples_leaf=30; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.28573363584388156, gb__learning_rate=0.040957144541603416, gb__max_depth=6, gb__max_leaf_nodes=17, gb__min_samples_leaf=97; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.28573363584388156, gb__learning_rate=0.040957144541603416, gb__max_depth=6, gb__max_leaf_nodes=17, gb__min_samples_leaf=97; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.28573363584388156, gb__learning_rate=0.040957144541603416, gb__max_depth=6, gb__max_leaf_nodes=17, gb__min_samples_leaf=97; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.31203728088487304, gb__learning_rate=0.0024345423962016913, gb__max_depth=9, gb__max_leaf_nodes=132, gb__min_samples_leaf=109; total time=   4.3s\n",
      "[CV] END gb__l2_regularization=0.31203728088487304, gb__learning_rate=0.0024345423962016913, gb__max_depth=9, gb__max_leaf_nodes=132, gb__min_samples_leaf=109; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=0.31203728088487304, gb__learning_rate=0.0024345423962016913, gb__max_depth=9, gb__max_leaf_nodes=132, gb__min_samples_leaf=109; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=0.31203728088487304, gb__learning_rate=0.0024345423962016913, gb__max_depth=9, gb__max_leaf_nodes=132, gb__min_samples_leaf=109; total time=   4.3s\n",
      "[CV] END gb__l2_regularization=0.31203728088487304, gb__learning_rate=0.0024345423962016913, gb__max_depth=9, gb__max_leaf_nodes=132, gb__min_samples_leaf=109; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=0.28573363584388156, gb__learning_rate=0.040957144541603416, gb__max_depth=6, gb__max_leaf_nodes=17, gb__min_samples_leaf=97; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.28573363584388156, gb__learning_rate=0.040957144541603416, gb__max_depth=6, gb__max_leaf_nodes=17, gb__min_samples_leaf=97; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.0495128632644757, gb__learning_rate=0.01174843954800703, gb__max_depth=2, gb__max_leaf_nodes=234, gb__min_samples_leaf=68; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.6648852816008435, gb__learning_rate=0.0033572967053517922, gb__max_depth=6, gb__max_leaf_nodes=176, gb__min_samples_leaf=67; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=1.6648852816008435, gb__learning_rate=0.0033572967053517922, gb__max_depth=6, gb__max_leaf_nodes=176, gb__min_samples_leaf=67; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.0495128632644757, gb__learning_rate=0.01174843954800703, gb__max_depth=2, gb__max_leaf_nodes=234, gb__min_samples_leaf=68; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.0495128632644757, gb__learning_rate=0.01174843954800703, gb__max_depth=2, gb__max_leaf_nodes=234, gb__min_samples_leaf=68; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.6648852816008435, gb__learning_rate=0.0033572967053517922, gb__max_depth=6, gb__max_leaf_nodes=176, gb__min_samples_leaf=67; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=1.6648852816008435, gb__learning_rate=0.0033572967053517922, gb__max_depth=6, gb__max_leaf_nodes=176, gb__min_samples_leaf=67; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.6648852816008435, gb__learning_rate=0.0033572967053517922, gb__max_depth=6, gb__max_leaf_nodes=176, gb__min_samples_leaf=67; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.0495128632644757, gb__learning_rate=0.01174843954800703, gb__max_depth=2, gb__max_leaf_nodes=234, gb__min_samples_leaf=68; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.0495128632644757, gb__learning_rate=0.01174843954800703, gb__max_depth=2, gb__max_leaf_nodes=234, gb__min_samples_leaf=68; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.799721943430511, gb__learning_rate=0.0013049579160355222, gb__max_depth=4, gb__max_leaf_nodes=123, gb__min_samples_leaf=64; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.799721943430511, gb__learning_rate=0.0013049579160355222, gb__max_depth=4, gb__max_leaf_nodes=123, gb__min_samples_leaf=64; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.799721943430511, gb__learning_rate=0.0013049579160355222, gb__max_depth=4, gb__max_leaf_nodes=123, gb__min_samples_leaf=64; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.799721943430511, gb__learning_rate=0.0013049579160355222, gb__max_depth=4, gb__max_leaf_nodes=123, gb__min_samples_leaf=64; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.799721943430511, gb__learning_rate=0.0013049579160355222, gb__max_depth=4, gb__max_leaf_nodes=123, gb__min_samples_leaf=64; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.9664617716135764, gb__learning_rate=0.014329409164607492, gb__max_depth=6, gb__max_leaf_nodes=66, gb__min_samples_leaf=144; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.9664617716135764, gb__learning_rate=0.014329409164607492, gb__max_depth=6, gb__max_leaf_nodes=66, gb__min_samples_leaf=144; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.9664617716135764, gb__learning_rate=0.014329409164607492, gb__max_depth=6, gb__max_leaf_nodes=66, gb__min_samples_leaf=144; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.34104824737458306, gb__learning_rate=0.0014492412389916862, gb__max_depth=5, gb__max_leaf_nodes=104, gb__min_samples_leaf=69; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=1.9664617716135764, gb__learning_rate=0.014329409164607492, gb__max_depth=6, gb__max_leaf_nodes=66, gb__min_samples_leaf=144; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.34104824737458306, gb__learning_rate=0.0014492412389916862, gb__max_depth=5, gb__max_leaf_nodes=104, gb__min_samples_leaf=69; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.9664617716135764, gb__learning_rate=0.014329409164607492, gb__max_depth=6, gb__max_leaf_nodes=66, gb__min_samples_leaf=144; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=0.34104824737458306, gb__learning_rate=0.0014492412389916862, gb__max_depth=5, gb__max_leaf_nodes=104, gb__min_samples_leaf=69; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=0.34104824737458306, gb__learning_rate=0.0014492412389916862, gb__max_depth=5, gb__max_leaf_nodes=104, gb__min_samples_leaf=69; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.34104824737458306, gb__learning_rate=0.0014492412389916862, gb__max_depth=5, gb__max_leaf_nodes=104, gb__min_samples_leaf=69; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=1.1265764356910786, gb__learning_rate=0.00900997135734756, gb__max_depth=6, gb__max_leaf_nodes=145, gb__min_samples_leaf=93; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=0.48205093205202343, gb__learning_rate=0.04926364988526881, gb__max_depth=9, gb__max_leaf_nodes=190, gb__min_samples_leaf=44; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.1265764356910786, gb__learning_rate=0.00900997135734756, gb__max_depth=6, gb__max_leaf_nodes=145, gb__min_samples_leaf=93; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.48205093205202343, gb__learning_rate=0.04926364988526881, gb__max_depth=9, gb__max_leaf_nodes=190, gb__min_samples_leaf=44; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.1265764356910786, gb__learning_rate=0.00900997135734756, gb__max_depth=6, gb__max_leaf_nodes=145, gb__min_samples_leaf=93; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=0.48205093205202343, gb__learning_rate=0.04926364988526881, gb__max_depth=9, gb__max_leaf_nodes=190, gb__min_samples_leaf=44; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.1265764356910786, gb__learning_rate=0.00900997135734756, gb__max_depth=6, gb__max_leaf_nodes=145, gb__min_samples_leaf=93; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=1.1265764356910786, gb__learning_rate=0.00900997135734756, gb__max_depth=6, gb__max_leaf_nodes=145, gb__min_samples_leaf=93; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=0.48205093205202343, gb__learning_rate=0.04926364988526881, gb__max_depth=9, gb__max_leaf_nodes=190, gb__min_samples_leaf=44; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.48205093205202343, gb__learning_rate=0.04926364988526881, gb__max_depth=9, gb__max_leaf_nodes=190, gb__min_samples_leaf=44; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.8503117489824894, gb__learning_rate=0.003274135983403057, gb__max_depth=5, gb__max_leaf_nodes=69, gb__min_samples_leaf=200; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.8503117489824894, gb__learning_rate=0.003274135983403057, gb__max_depth=5, gb__max_leaf_nodes=69, gb__min_samples_leaf=200; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.8503117489824894, gb__learning_rate=0.003274135983403057, gb__max_depth=5, gb__max_leaf_nodes=69, gb__min_samples_leaf=200; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.8186408041575641, gb__learning_rate=0.004375517173207359, gb__max_depth=9, gb__max_leaf_nodes=147, gb__min_samples_leaf=11; total time=   5.2s\n",
      "[CV] END gb__l2_regularization=1.8186408041575641, gb__learning_rate=0.004375517173207359, gb__max_depth=9, gb__max_leaf_nodes=147, gb__min_samples_leaf=11; total time=   5.2s\n",
      "[CV] END gb__l2_regularization=1.8186408041575641, gb__learning_rate=0.004375517173207359, gb__max_depth=9, gb__max_leaf_nodes=147, gb__min_samples_leaf=11; total time=   5.4s\n",
      "[CV] END gb__l2_regularization=1.8186408041575641, gb__learning_rate=0.004375517173207359, gb__max_depth=9, gb__max_leaf_nodes=147, gb__min_samples_leaf=11; total time=   5.3s\n",
      "[CV] END gb__l2_regularization=0.8503117489824894, gb__learning_rate=0.003274135983403057, gb__max_depth=5, gb__max_leaf_nodes=69, gb__min_samples_leaf=200; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.8186408041575641, gb__learning_rate=0.004375517173207359, gb__max_depth=9, gb__max_leaf_nodes=147, gb__min_samples_leaf=11; total time=   5.4s\n",
      "[CV] END gb__l2_regularization=0.8503117489824894, gb__learning_rate=0.003274135983403057, gb__max_depth=5, gb__max_leaf_nodes=69, gb__min_samples_leaf=200; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.684569549189997, gb__learning_rate=0.013004555820744673, gb__max_depth=5, gb__max_leaf_nodes=29, gb__min_samples_leaf=104; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.684569549189997, gb__learning_rate=0.013004555820744673, gb__max_depth=5, gb__max_leaf_nodes=29, gb__min_samples_leaf=104; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.684569549189997, gb__learning_rate=0.013004555820744673, gb__max_depth=5, gb__max_leaf_nodes=29, gb__min_samples_leaf=104; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.684569549189997, gb__learning_rate=0.013004555820744673, gb__max_depth=5, gb__max_leaf_nodes=29, gb__min_samples_leaf=104; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.684569549189997, gb__learning_rate=0.013004555820744673, gb__max_depth=5, gb__max_leaf_nodes=29, gb__min_samples_leaf=104; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.6890676973563028, gb__learning_rate=0.0709908749648402, gb__max_depth=6, gb__max_leaf_nodes=39, gb__min_samples_leaf=163; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.8437484700462337, gb__learning_rate=0.0016565580440884786, gb__max_depth=8, gb__max_leaf_nodes=205, gb__min_samples_leaf=49; total time=   4.0s\n",
      "[CV] END gb__l2_regularization=1.6890676973563028, gb__learning_rate=0.0709908749648402, gb__max_depth=6, gb__max_leaf_nodes=39, gb__min_samples_leaf=163; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.8437484700462337, gb__learning_rate=0.0016565580440884786, gb__max_depth=8, gb__max_leaf_nodes=205, gb__min_samples_leaf=49; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=1.6890676973563028, gb__learning_rate=0.0709908749648402, gb__max_depth=6, gb__max_leaf_nodes=39, gb__min_samples_leaf=163; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.8437484700462337, gb__learning_rate=0.0016565580440884786, gb__max_depth=8, gb__max_leaf_nodes=205, gb__min_samples_leaf=49; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=1.8437484700462337, gb__learning_rate=0.0016565580440884786, gb__max_depth=8, gb__max_leaf_nodes=205, gb__min_samples_leaf=49; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=1.6890676973563028, gb__learning_rate=0.0709908749648402, gb__max_depth=6, gb__max_leaf_nodes=39, gb__min_samples_leaf=163; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.6890676973563028, gb__learning_rate=0.0709908749648402, gb__max_depth=6, gb__max_leaf_nodes=39, gb__min_samples_leaf=163; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.930510614528276, gb__learning_rate=0.03189315160363524, gb__max_depth=10, gb__max_leaf_nodes=172, gb__min_samples_leaf=24; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.8437484700462337, gb__learning_rate=0.0016565580440884786, gb__max_depth=8, gb__max_leaf_nodes=205, gb__min_samples_leaf=49; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.930510614528276, gb__learning_rate=0.03189315160363524, gb__max_depth=10, gb__max_leaf_nodes=172, gb__min_samples_leaf=24; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.930510614528276, gb__learning_rate=0.03189315160363524, gb__max_depth=10, gb__max_leaf_nodes=172, gb__min_samples_leaf=24; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=1.930510614528276, gb__learning_rate=0.03189315160363524, gb__max_depth=10, gb__max_leaf_nodes=172, gb__min_samples_leaf=24; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.930510614528276, gb__learning_rate=0.03189315160363524, gb__max_depth=10, gb__max_leaf_nodes=172, gb__min_samples_leaf=24; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.3974313630683448, gb__learning_rate=0.0010319982330247674, gb__max_depth=4, gb__max_leaf_nodes=96, gb__min_samples_leaf=145; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.3974313630683448, gb__learning_rate=0.0010319982330247674, gb__max_depth=4, gb__max_leaf_nodes=96, gb__min_samples_leaf=145; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.3974313630683448, gb__learning_rate=0.0010319982330247674, gb__max_depth=4, gb__max_leaf_nodes=96, gb__min_samples_leaf=145; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.330533878126005, gb__learning_rate=0.0010932847127976988, gb__max_depth=10, gb__max_leaf_nodes=103, gb__min_samples_leaf=138; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=0.330533878126005, gb__learning_rate=0.0010932847127976988, gb__max_depth=10, gb__max_leaf_nodes=103, gb__min_samples_leaf=138; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=1.4580143360819746, gb__learning_rate=0.08138233922650512, gb__max_depth=6, gb__max_leaf_nodes=249, gb__min_samples_leaf=50; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.330533878126005, gb__learning_rate=0.0010932847127976988, gb__max_depth=10, gb__max_leaf_nodes=103, gb__min_samples_leaf=138; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=0.330533878126005, gb__learning_rate=0.0010932847127976988, gb__max_depth=10, gb__max_leaf_nodes=103, gb__min_samples_leaf=138; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=0.330533878126005, gb__learning_rate=0.0010932847127976988, gb__max_depth=10, gb__max_leaf_nodes=103, gb__min_samples_leaf=138; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=0.3974313630683448, gb__learning_rate=0.0010319982330247674, gb__max_depth=4, gb__max_leaf_nodes=96, gb__min_samples_leaf=145; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.4580143360819746, gb__learning_rate=0.08138233922650512, gb__max_depth=6, gb__max_leaf_nodes=249, gb__min_samples_leaf=50; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=0.3974313630683448, gb__learning_rate=0.0010319982330247674, gb__max_depth=4, gb__max_leaf_nodes=96, gb__min_samples_leaf=145; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.4580143360819746, gb__learning_rate=0.08138233922650512, gb__max_depth=6, gb__max_leaf_nodes=249, gb__min_samples_leaf=50; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.4580143360819746, gb__learning_rate=0.08138233922650512, gb__max_depth=6, gb__max_leaf_nodes=249, gb__min_samples_leaf=50; total time=   1.0s\n",
      "[CV] END gb__l2_regularization=1.4580143360819746, gb__learning_rate=0.08138233922650512, gb__max_depth=6, gb__max_leaf_nodes=249, gb__min_samples_leaf=50; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.8299193510875615, gb__learning_rate=0.12754065069696732, gb__max_depth=3, gb__max_leaf_nodes=48, gb__min_samples_leaf=57; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.8299193510875615, gb__learning_rate=0.12754065069696732, gb__max_depth=3, gb__max_leaf_nodes=48, gb__min_samples_leaf=57; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.8299193510875615, gb__learning_rate=0.12754065069696732, gb__max_depth=3, gb__max_leaf_nodes=48, gb__min_samples_leaf=57; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.8299193510875615, gb__learning_rate=0.12754065069696732, gb__max_depth=3, gb__max_leaf_nodes=48, gb__min_samples_leaf=57; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.8299193510875615, gb__learning_rate=0.12754065069696732, gb__max_depth=3, gb__max_leaf_nodes=48, gb__min_samples_leaf=57; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.7416365043965327, gb__learning_rate=0.04537335394667876, gb__max_depth=6, gb__max_leaf_nodes=114, gb__min_samples_leaf=181; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.7416365043965327, gb__learning_rate=0.04537335394667876, gb__max_depth=6, gb__max_leaf_nodes=114, gb__min_samples_leaf=181; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.2751149427104262, gb__learning_rate=0.1576643635794309, gb__max_depth=2, gb__max_leaf_nodes=242, gb__min_samples_leaf=110; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.7416365043965327, gb__learning_rate=0.04537335394667876, gb__max_depth=6, gb__max_leaf_nodes=114, gb__min_samples_leaf=181; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.2751149427104262, gb__learning_rate=0.1576643635794309, gb__max_depth=2, gb__max_leaf_nodes=242, gb__min_samples_leaf=110; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.2751149427104262, gb__learning_rate=0.1576643635794309, gb__max_depth=2, gb__max_leaf_nodes=242, gb__min_samples_leaf=110; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.7416365043965327, gb__learning_rate=0.04537335394667876, gb__max_depth=6, gb__max_leaf_nodes=114, gb__min_samples_leaf=181; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.7416365043965327, gb__learning_rate=0.04537335394667876, gb__max_depth=6, gb__max_leaf_nodes=114, gb__min_samples_leaf=181; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.9434241907782075, gb__learning_rate=0.1267250518284891, gb__max_depth=6, gb__max_leaf_nodes=233, gb__min_samples_leaf=151; total time=   0.9s\n",
      "[CV] END gb__l2_regularization=1.9434241907782075, gb__learning_rate=0.1267250518284891, gb__max_depth=6, gb__max_leaf_nodes=233, gb__min_samples_leaf=151; total time=   1.0s\n",
      "[CV] END gb__l2_regularization=1.2751149427104262, gb__learning_rate=0.1576643635794309, gb__max_depth=2, gb__max_leaf_nodes=242, gb__min_samples_leaf=110; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.9434241907782075, gb__learning_rate=0.1267250518284891, gb__max_depth=6, gb__max_leaf_nodes=233, gb__min_samples_leaf=151; total time=   1.1s\n",
      "[CV] END gb__l2_regularization=1.2751149427104262, gb__learning_rate=0.1576643635794309, gb__max_depth=2, gb__max_leaf_nodes=242, gb__min_samples_leaf=110; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.9434241907782075, gb__learning_rate=0.1267250518284891, gb__max_depth=6, gb__max_leaf_nodes=233, gb__min_samples_leaf=151; total time=   0.9s\n",
      "[CV] END gb__l2_regularization=1.9434241907782075, gb__learning_rate=0.1267250518284891, gb__max_depth=6, gb__max_leaf_nodes=233, gb__min_samples_leaf=151; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=0.9875911927287815, gb__learning_rate=0.019718442220616167, gb__max_depth=4, gb__max_leaf_nodes=78, gb__min_samples_leaf=105; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.9875911927287815, gb__learning_rate=0.019718442220616167, gb__max_depth=4, gb__max_leaf_nodes=78, gb__min_samples_leaf=105; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.9875911927287815, gb__learning_rate=0.019718442220616167, gb__max_depth=4, gb__max_leaf_nodes=78, gb__min_samples_leaf=105; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.9875911927287815, gb__learning_rate=0.019718442220616167, gb__max_depth=4, gb__max_leaf_nodes=78, gb__min_samples_leaf=105; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.9875911927287815, gb__learning_rate=0.019718442220616167, gb__max_depth=4, gb__max_leaf_nodes=78, gb__min_samples_leaf=105; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.2728208225275608, gb__learning_rate=0.00600755675334899, gb__max_depth=5, gb__max_leaf_nodes=237, gb__min_samples_leaf=160; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.2728208225275608, gb__learning_rate=0.00600755675334899, gb__max_depth=5, gb__max_leaf_nodes=237, gb__min_samples_leaf=160; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.2728208225275608, gb__learning_rate=0.00600755675334899, gb__max_depth=5, gb__max_leaf_nodes=237, gb__min_samples_leaf=160; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.2728208225275608, gb__learning_rate=0.00600755675334899, gb__max_depth=5, gb__max_leaf_nodes=237, gb__min_samples_leaf=160; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.2088347585556345, gb__learning_rate=0.021739614639581923, gb__max_depth=5, gb__max_leaf_nodes=28, gb__min_samples_leaf=169; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.2088347585556345, gb__learning_rate=0.021739614639581923, gb__max_depth=5, gb__max_leaf_nodes=28, gb__min_samples_leaf=169; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.2088347585556345, gb__learning_rate=0.021739614639581923, gb__max_depth=5, gb__max_leaf_nodes=28, gb__min_samples_leaf=169; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.2728208225275608, gb__learning_rate=0.00600755675334899, gb__max_depth=5, gb__max_leaf_nodes=237, gb__min_samples_leaf=160; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.197730932977072, gb__learning_rate=0.05260978477210602, gb__max_depth=3, gb__max_leaf_nodes=185, gb__min_samples_leaf=54; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.2088347585556345, gb__learning_rate=0.021739614639581923, gb__max_depth=5, gb__max_leaf_nodes=28, gb__min_samples_leaf=169; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.2088347585556345, gb__learning_rate=0.021739614639581923, gb__max_depth=5, gb__max_leaf_nodes=28, gb__min_samples_leaf=169; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.197730932977072, gb__learning_rate=0.05260978477210602, gb__max_depth=3, gb__max_leaf_nodes=185, gb__min_samples_leaf=54; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.197730932977072, gb__learning_rate=0.05260978477210602, gb__max_depth=3, gb__max_leaf_nodes=185, gb__min_samples_leaf=54; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.197730932977072, gb__learning_rate=0.05260978477210602, gb__max_depth=3, gb__max_leaf_nodes=185, gb__min_samples_leaf=54; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.197730932977072, gb__learning_rate=0.05260978477210602, gb__max_depth=3, gb__max_leaf_nodes=185, gb__min_samples_leaf=54; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.591267371675428, gb__learning_rate=0.001825248807094868, gb__max_depth=5, gb__max_leaf_nodes=45, gb__min_samples_leaf=199; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.0786844838313014, gb__learning_rate=0.10002928632464418, gb__max_depth=10, gb__max_leaf_nodes=246, gb__min_samples_leaf=199; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=1.0786844838313014, gb__learning_rate=0.10002928632464418, gb__max_depth=10, gb__max_leaf_nodes=246, gb__min_samples_leaf=199; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=0.591267371675428, gb__learning_rate=0.001825248807094868, gb__max_depth=5, gb__max_leaf_nodes=45, gb__min_samples_leaf=199; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.0786844838313014, gb__learning_rate=0.10002928632464418, gb__max_depth=10, gb__max_leaf_nodes=246, gb__min_samples_leaf=199; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.591267371675428, gb__learning_rate=0.001825248807094868, gb__max_depth=5, gb__max_leaf_nodes=45, gb__min_samples_leaf=199; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.591267371675428, gb__learning_rate=0.001825248807094868, gb__max_depth=5, gb__max_leaf_nodes=45, gb__min_samples_leaf=199; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.591267371675428, gb__learning_rate=0.001825248807094868, gb__max_depth=5, gb__max_leaf_nodes=45, gb__min_samples_leaf=199; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.0786844838313014, gb__learning_rate=0.10002928632464418, gb__max_depth=10, gb__max_leaf_nodes=246, gb__min_samples_leaf=199; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=1.0786844838313014, gb__learning_rate=0.10002928632464418, gb__max_depth=10, gb__max_leaf_nodes=246, gb__min_samples_leaf=199; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.013904261062381407, gb__learning_rate=0.018415478124479582, gb__max_depth=10, gb__max_leaf_nodes=77, gb__min_samples_leaf=174; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.013904261062381407, gb__learning_rate=0.018415478124479582, gb__max_depth=10, gb__max_leaf_nodes=77, gb__min_samples_leaf=174; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.013904261062381407, gb__learning_rate=0.018415478124479582, gb__max_depth=10, gb__max_leaf_nodes=77, gb__min_samples_leaf=174; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.22010384905535352, gb__learning_rate=0.0036696364068833334, gb__max_depth=10, gb__max_leaf_nodes=131, gb__min_samples_leaf=12; total time=   5.4s\n",
      "[CV] END gb__l2_regularization=0.22010384905535352, gb__learning_rate=0.0036696364068833334, gb__max_depth=10, gb__max_leaf_nodes=131, gb__min_samples_leaf=12; total time=   5.6s\n",
      "[CV] END gb__l2_regularization=0.22010384905535352, gb__learning_rate=0.0036696364068833334, gb__max_depth=10, gb__max_leaf_nodes=131, gb__min_samples_leaf=12; total time=   5.5s\n",
      "[CV] END gb__l2_regularization=0.22010384905535352, gb__learning_rate=0.0036696364068833334, gb__max_depth=10, gb__max_leaf_nodes=131, gb__min_samples_leaf=12; total time=   5.5s\n",
      "[CV] END gb__l2_regularization=0.22010384905535352, gb__learning_rate=0.0036696364068833334, gb__max_depth=10, gb__max_leaf_nodes=131, gb__min_samples_leaf=12; total time=   5.5s\n",
      "[CV] END gb__l2_regularization=0.013904261062381407, gb__learning_rate=0.018415478124479582, gb__max_depth=10, gb__max_leaf_nodes=77, gb__min_samples_leaf=174; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.013904261062381407, gb__learning_rate=0.018415478124479582, gb__max_depth=10, gb__max_leaf_nodes=77, gb__min_samples_leaf=174; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.3848720657805407, gb__learning_rate=0.004649079987978043, gb__max_depth=9, gb__max_leaf_nodes=222, gb__min_samples_leaf=68; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=0.6464058640415105, gb__learning_rate=0.019280010934335175, gb__max_depth=10, gb__max_leaf_nodes=195, gb__min_samples_leaf=122; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.3848720657805407, gb__learning_rate=0.004649079987978043, gb__max_depth=9, gb__max_leaf_nodes=222, gb__min_samples_leaf=68; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=1.3848720657805407, gb__learning_rate=0.004649079987978043, gb__max_depth=9, gb__max_leaf_nodes=222, gb__min_samples_leaf=68; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=1.3848720657805407, gb__learning_rate=0.004649079987978043, gb__max_depth=9, gb__max_leaf_nodes=222, gb__min_samples_leaf=68; total time=   4.4s\n",
      "[CV] END gb__l2_regularization=1.3848720657805407, gb__learning_rate=0.004649079987978043, gb__max_depth=9, gb__max_leaf_nodes=222, gb__min_samples_leaf=68; total time=   4.5s\n",
      "[CV] END gb__l2_regularization=0.6464058640415105, gb__learning_rate=0.019280010934335175, gb__max_depth=10, gb__max_leaf_nodes=195, gb__min_samples_leaf=122; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.6464058640415105, gb__learning_rate=0.019280010934335175, gb__max_depth=10, gb__max_leaf_nodes=195, gb__min_samples_leaf=122; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.6464058640415105, gb__learning_rate=0.019280010934335175, gb__max_depth=10, gb__max_leaf_nodes=195, gb__min_samples_leaf=122; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.6464058640415105, gb__learning_rate=0.019280010934335175, gb__max_depth=10, gb__max_leaf_nodes=195, gb__min_samples_leaf=122; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.6017566196335393, gb__learning_rate=0.005076734398297609, gb__max_depth=2, gb__max_leaf_nodes=202, gb__min_samples_leaf=122; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.12978449421796312, gb__learning_rate=0.004255780974870929, gb__max_depth=8, gb__max_leaf_nodes=145, gb__min_samples_leaf=140; total time=   3.7s\n",
      "[CV] END gb__l2_regularization=0.12978449421796312, gb__learning_rate=0.004255780974870929, gb__max_depth=8, gb__max_leaf_nodes=145, gb__min_samples_leaf=140; total time=   3.8s\n",
      "[CV] END gb__l2_regularization=0.12978449421796312, gb__learning_rate=0.004255780974870929, gb__max_depth=8, gb__max_leaf_nodes=145, gb__min_samples_leaf=140; total time=   3.8s\n",
      "[CV] END gb__l2_regularization=0.6017566196335393, gb__learning_rate=0.005076734398297609, gb__max_depth=2, gb__max_leaf_nodes=202, gb__min_samples_leaf=122; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.12978449421796312, gb__learning_rate=0.004255780974870929, gb__max_depth=8, gb__max_leaf_nodes=145, gb__min_samples_leaf=140; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=0.6017566196335393, gb__learning_rate=0.005076734398297609, gb__max_depth=2, gb__max_leaf_nodes=202, gb__min_samples_leaf=122; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.6017566196335393, gb__learning_rate=0.005076734398297609, gb__max_depth=2, gb__max_leaf_nodes=202, gb__min_samples_leaf=122; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.12978449421796312, gb__learning_rate=0.004255780974870929, gb__max_depth=8, gb__max_leaf_nodes=145, gb__min_samples_leaf=140; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=0.6017566196335393, gb__learning_rate=0.005076734398297609, gb__max_depth=2, gb__max_leaf_nodes=202, gb__min_samples_leaf=122; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.9532299116653058, gb__learning_rate=0.010427699854447888, gb__max_depth=8, gb__max_leaf_nodes=244, gb__min_samples_leaf=138; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.9532299116653058, gb__learning_rate=0.010427699854447888, gb__max_depth=8, gb__max_leaf_nodes=244, gb__min_samples_leaf=138; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=1.9532299116653058, gb__learning_rate=0.010427699854447888, gb__max_depth=8, gb__max_leaf_nodes=244, gb__min_samples_leaf=138; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.9532299116653058, gb__learning_rate=0.010427699854447888, gb__max_depth=8, gb__max_leaf_nodes=244, gb__min_samples_leaf=138; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.9532299116653058, gb__learning_rate=0.010427699854447888, gb__max_depth=8, gb__max_leaf_nodes=244, gb__min_samples_leaf=138; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.47912378133394484, gb__learning_rate=0.0022851892235553474, gb__max_depth=7, gb__max_leaf_nodes=175, gb__min_samples_leaf=77; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.47912378133394484, gb__learning_rate=0.0022851892235553474, gb__max_depth=7, gb__max_leaf_nodes=175, gb__min_samples_leaf=77; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.47912378133394484, gb__learning_rate=0.0022851892235553474, gb__max_depth=7, gb__max_leaf_nodes=175, gb__min_samples_leaf=77; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.1617066526654305, gb__learning_rate=0.008235290243835798, gb__max_depth=2, gb__max_leaf_nodes=53, gb__min_samples_leaf=33; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.1617066526654305, gb__learning_rate=0.008235290243835798, gb__max_depth=2, gb__max_leaf_nodes=53, gb__min_samples_leaf=33; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.1617066526654305, gb__learning_rate=0.008235290243835798, gb__max_depth=2, gb__max_leaf_nodes=53, gb__min_samples_leaf=33; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.9406012688920768, gb__learning_rate=0.27293445538868294, gb__max_depth=7, gb__max_leaf_nodes=154, gb__min_samples_leaf=153; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.9406012688920768, gb__learning_rate=0.27293445538868294, gb__max_depth=7, gb__max_leaf_nodes=154, gb__min_samples_leaf=153; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.9406012688920768, gb__learning_rate=0.27293445538868294, gb__max_depth=7, gb__max_leaf_nodes=154, gb__min_samples_leaf=153; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=0.1617066526654305, gb__learning_rate=0.008235290243835798, gb__max_depth=2, gb__max_leaf_nodes=53, gb__min_samples_leaf=33; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.9406012688920768, gb__learning_rate=0.27293445538868294, gb__max_depth=7, gb__max_leaf_nodes=154, gb__min_samples_leaf=153; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.9406012688920768, gb__learning_rate=0.27293445538868294, gb__max_depth=7, gb__max_leaf_nodes=154, gb__min_samples_leaf=153; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.1617066526654305, gb__learning_rate=0.008235290243835798, gb__max_depth=2, gb__max_leaf_nodes=53, gb__min_samples_leaf=33; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.47912378133394484, gb__learning_rate=0.0022851892235553474, gb__max_depth=7, gb__max_leaf_nodes=175, gb__min_samples_leaf=77; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.47912378133394484, gb__learning_rate=0.0022851892235553474, gb__max_depth=7, gb__max_leaf_nodes=175, gb__min_samples_leaf=77; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.670604991178476, gb__learning_rate=0.006231765707605582, gb__max_depth=7, gb__max_leaf_nodes=223, gb__min_samples_leaf=102; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.670604991178476, gb__learning_rate=0.006231765707605582, gb__max_depth=7, gb__max_leaf_nodes=223, gb__min_samples_leaf=102; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=1.670604991178476, gb__learning_rate=0.006231765707605582, gb__max_depth=7, gb__max_leaf_nodes=223, gb__min_samples_leaf=102; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.7167176096274397, gb__learning_rate=0.006418591434788316, gb__max_depth=5, gb__max_leaf_nodes=162, gb__min_samples_leaf=99; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.670604991178476, gb__learning_rate=0.006231765707605582, gb__max_depth=7, gb__max_leaf_nodes=223, gb__min_samples_leaf=102; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=1.7167176096274397, gb__learning_rate=0.006418591434788316, gb__max_depth=5, gb__max_leaf_nodes=162, gb__min_samples_leaf=99; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.670604991178476, gb__learning_rate=0.006231765707605582, gb__max_depth=7, gb__max_leaf_nodes=223, gb__min_samples_leaf=102; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.7167176096274397, gb__learning_rate=0.006418591434788316, gb__max_depth=5, gb__max_leaf_nodes=162, gb__min_samples_leaf=99; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.7167176096274397, gb__learning_rate=0.006418591434788316, gb__max_depth=5, gb__max_leaf_nodes=162, gb__min_samples_leaf=99; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.7167176096274397, gb__learning_rate=0.006418591434788316, gb__max_depth=5, gb__max_leaf_nodes=162, gb__min_samples_leaf=99; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.024186116598562, gb__learning_rate=0.0036396322020758602, gb__max_depth=8, gb__max_leaf_nodes=67, gb__min_samples_leaf=170; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.024186116598562, gb__learning_rate=0.0036396322020758602, gb__max_depth=8, gb__max_leaf_nodes=67, gb__min_samples_leaf=170; total time=   3.7s\n",
      "[CV] END gb__l2_regularization=1.024186116598562, gb__learning_rate=0.0036396322020758602, gb__max_depth=8, gb__max_leaf_nodes=67, gb__min_samples_leaf=170; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.024186116598562, gb__learning_rate=0.0036396322020758602, gb__max_depth=8, gb__max_leaf_nodes=67, gb__min_samples_leaf=170; total time=   3.6s\n",
      "[CV] END gb__l2_regularization=1.024186116598562, gb__learning_rate=0.0036396322020758602, gb__max_depth=8, gb__max_leaf_nodes=67, gb__min_samples_leaf=170; total time=   3.6s\n",
      "[CV] END gb__l2_regularization=0.7951440421750446, gb__learning_rate=0.01916606139735684, gb__max_depth=9, gb__max_leaf_nodes=144, gb__min_samples_leaf=20; total time=   3.7s\n",
      "[CV] END gb__l2_regularization=0.7951440421750446, gb__learning_rate=0.01916606139735684, gb__max_depth=9, gb__max_leaf_nodes=144, gb__min_samples_leaf=20; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.7951440421750446, gb__learning_rate=0.01916606139735684, gb__max_depth=9, gb__max_leaf_nodes=144, gb__min_samples_leaf=20; total time=   3.6s\n",
      "[CV] END gb__l2_regularization=0.7951440421750446, gb__learning_rate=0.01916606139735684, gb__max_depth=9, gb__max_leaf_nodes=144, gb__min_samples_leaf=20; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=0.7951440421750446, gb__learning_rate=0.01916606139735684, gb__max_depth=9, gb__max_leaf_nodes=144, gb__min_samples_leaf=20; total time=   3.6s\n",
      "[CV] END gb__l2_regularization=0.682132702100517, gb__learning_rate=0.0019102388408183122, gb__max_depth=8, gb__max_leaf_nodes=174, gb__min_samples_leaf=51; total time=   4.0s\n",
      "[CV] END gb__l2_regularization=0.682132702100517, gb__learning_rate=0.0019102388408183122, gb__max_depth=8, gb__max_leaf_nodes=174, gb__min_samples_leaf=51; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=0.682132702100517, gb__learning_rate=0.0019102388408183122, gb__max_depth=8, gb__max_leaf_nodes=174, gb__min_samples_leaf=51; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=0.682132702100517, gb__learning_rate=0.0019102388408183122, gb__max_depth=8, gb__max_leaf_nodes=174, gb__min_samples_leaf=51; total time=   4.2s\n",
      "[CV] END gb__l2_regularization=0.5158832554303112, gb__learning_rate=0.04313804987283086, gb__max_depth=10, gb__max_leaf_nodes=75, gb__min_samples_leaf=122; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.5158832554303112, gb__learning_rate=0.04313804987283086, gb__max_depth=10, gb__max_leaf_nodes=75, gb__min_samples_leaf=122; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.5158832554303112, gb__learning_rate=0.04313804987283086, gb__max_depth=10, gb__max_leaf_nodes=75, gb__min_samples_leaf=122; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.682132702100517, gb__learning_rate=0.0019102388408183122, gb__max_depth=8, gb__max_leaf_nodes=174, gb__min_samples_leaf=51; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=0.5158832554303112, gb__learning_rate=0.04313804987283086, gb__max_depth=10, gb__max_leaf_nodes=75, gb__min_samples_leaf=122; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.5158832554303112, gb__learning_rate=0.04313804987283086, gb__max_depth=10, gb__max_leaf_nodes=75, gb__min_samples_leaf=122; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.48370458180090337, gb__learning_rate=0.0017006966059793958, gb__max_depth=6, gb__max_leaf_nodes=52, gb__min_samples_leaf=169; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=0.48370458180090337, gb__learning_rate=0.0017006966059793958, gb__max_depth=6, gb__max_leaf_nodes=52, gb__min_samples_leaf=169; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=0.48370458180090337, gb__learning_rate=0.0017006966059793958, gb__max_depth=6, gb__max_leaf_nodes=52, gb__min_samples_leaf=169; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=0.48370458180090337, gb__learning_rate=0.0017006966059793958, gb__max_depth=6, gb__max_leaf_nodes=52, gb__min_samples_leaf=169; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.2662029145465359, gb__learning_rate=0.006915409486982814, gb__max_depth=4, gb__max_leaf_nodes=162, gb__min_samples_leaf=57; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.2662029145465359, gb__learning_rate=0.006915409486982814, gb__max_depth=4, gb__max_leaf_nodes=162, gb__min_samples_leaf=57; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.2662029145465359, gb__learning_rate=0.006915409486982814, gb__max_depth=4, gb__max_leaf_nodes=162, gb__min_samples_leaf=57; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.48370458180090337, gb__learning_rate=0.0017006966059793958, gb__max_depth=6, gb__max_leaf_nodes=52, gb__min_samples_leaf=169; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=1.6933222844766118, gb__learning_rate=0.1321962404466185, gb__max_depth=7, gb__max_leaf_nodes=135, gb__min_samples_leaf=170; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=1.6933222844766118, gb__learning_rate=0.1321962404466185, gb__max_depth=7, gb__max_leaf_nodes=135, gb__min_samples_leaf=170; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.6933222844766118, gb__learning_rate=0.1321962404466185, gb__max_depth=7, gb__max_leaf_nodes=135, gb__min_samples_leaf=170; total time=   1.1s\n",
      "[CV] END gb__l2_regularization=1.6933222844766118, gb__learning_rate=0.1321962404466185, gb__max_depth=7, gb__max_leaf_nodes=135, gb__min_samples_leaf=170; total time=   0.9s\n",
      "[CV] END gb__l2_regularization=1.6933222844766118, gb__learning_rate=0.1321962404466185, gb__max_depth=7, gb__max_leaf_nodes=135, gb__min_samples_leaf=170; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.2662029145465359, gb__learning_rate=0.006915409486982814, gb__max_depth=4, gb__max_leaf_nodes=162, gb__min_samples_leaf=57; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=1.2662029145465359, gb__learning_rate=0.006915409486982814, gb__max_depth=4, gb__max_leaf_nodes=162, gb__min_samples_leaf=57; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=1.2840632923085755, gb__learning_rate=0.0016159387509761451, gb__max_depth=9, gb__max_leaf_nodes=179, gb__min_samples_leaf=175; total time=   4.0s\n",
      "[CV] END gb__l2_regularization=1.2840632923085755, gb__learning_rate=0.0016159387509761451, gb__max_depth=9, gb__max_leaf_nodes=179, gb__min_samples_leaf=175; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.2840632923085755, gb__learning_rate=0.0016159387509761451, gb__max_depth=9, gb__max_leaf_nodes=179, gb__min_samples_leaf=175; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.3379765094284573, gb__learning_rate=0.02744297388220333, gb__max_depth=10, gb__max_leaf_nodes=114, gb__min_samples_leaf=162; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.3379765094284573, gb__learning_rate=0.02744297388220333, gb__max_depth=10, gb__max_leaf_nodes=114, gb__min_samples_leaf=162; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.3379765094284573, gb__learning_rate=0.02744297388220333, gb__max_depth=10, gb__max_leaf_nodes=114, gb__min_samples_leaf=162; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.2840632923085755, gb__learning_rate=0.0016159387509761451, gb__max_depth=9, gb__max_leaf_nodes=179, gb__min_samples_leaf=175; total time=   4.0s\n",
      "[CV] END gb__l2_regularization=1.2840632923085755, gb__learning_rate=0.0016159387509761451, gb__max_depth=9, gb__max_leaf_nodes=179, gb__min_samples_leaf=175; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=0.8968482859724947, gb__learning_rate=0.29066431570307705, gb__max_depth=5, gb__max_leaf_nodes=176, gb__min_samples_leaf=77; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=0.8968482859724947, gb__learning_rate=0.29066431570307705, gb__max_depth=5, gb__max_leaf_nodes=176, gb__min_samples_leaf=77; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.010123167692437374, gb__learning_rate=0.002502309600155433, gb__max_depth=3, gb__max_leaf_nodes=209, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.010123167692437374, gb__learning_rate=0.002502309600155433, gb__max_depth=3, gb__max_leaf_nodes=209, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.010123167692437374, gb__learning_rate=0.002502309600155433, gb__max_depth=3, gb__max_leaf_nodes=209, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.010123167692437374, gb__learning_rate=0.002502309600155433, gb__max_depth=3, gb__max_leaf_nodes=209, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.010123167692437374, gb__learning_rate=0.002502309600155433, gb__max_depth=3, gb__max_leaf_nodes=209, gb__min_samples_leaf=63; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=0.8968482859724947, gb__learning_rate=0.29066431570307705, gb__max_depth=5, gb__max_leaf_nodes=176, gb__min_samples_leaf=77; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.8968482859724947, gb__learning_rate=0.29066431570307705, gb__max_depth=5, gb__max_leaf_nodes=176, gb__min_samples_leaf=77; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=1.3379765094284573, gb__learning_rate=0.02744297388220333, gb__max_depth=10, gb__max_leaf_nodes=114, gb__min_samples_leaf=162; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.8968482859724947, gb__learning_rate=0.29066431570307705, gb__max_depth=5, gb__max_leaf_nodes=176, gb__min_samples_leaf=77; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.3379765094284573, gb__learning_rate=0.02744297388220333, gb__max_depth=10, gb__max_leaf_nodes=114, gb__min_samples_leaf=162; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=1.6984468209883559, gb__learning_rate=0.04255855490727933, gb__max_depth=2, gb__max_leaf_nodes=191, gb__min_samples_leaf=196; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.6984468209883559, gb__learning_rate=0.04255855490727933, gb__max_depth=2, gb__max_leaf_nodes=191, gb__min_samples_leaf=196; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.6984468209883559, gb__learning_rate=0.04255855490727933, gb__max_depth=2, gb__max_leaf_nodes=191, gb__min_samples_leaf=196; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.47449817499360014, gb__learning_rate=0.006398151340670027, gb__max_depth=5, gb__max_leaf_nodes=143, gb__min_samples_leaf=145; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.47449817499360014, gb__learning_rate=0.006398151340670027, gb__max_depth=5, gb__max_leaf_nodes=143, gb__min_samples_leaf=145; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.47449817499360014, gb__learning_rate=0.006398151340670027, gb__max_depth=5, gb__max_leaf_nodes=143, gb__min_samples_leaf=145; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=0.47449817499360014, gb__learning_rate=0.006398151340670027, gb__max_depth=5, gb__max_leaf_nodes=143, gb__min_samples_leaf=145; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.47449817499360014, gb__learning_rate=0.006398151340670027, gb__max_depth=5, gb__max_leaf_nodes=143, gb__min_samples_leaf=145; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.6984468209883559, gb__learning_rate=0.04255855490727933, gb__max_depth=2, gb__max_leaf_nodes=191, gb__min_samples_leaf=196; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.6984468209883559, gb__learning_rate=0.04255855490727933, gb__max_depth=2, gb__max_leaf_nodes=191, gb__min_samples_leaf=196; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.9734843059189102, gb__learning_rate=0.17559678733876366, gb__max_depth=3, gb__max_leaf_nodes=36, gb__min_samples_leaf=39; total time=   0.9s\n",
      "[CV] END gb__l2_regularization=0.9734843059189102, gb__learning_rate=0.17559678733876366, gb__max_depth=3, gb__max_leaf_nodes=36, gb__min_samples_leaf=39; total time=   1.1s\n",
      "[CV] END gb__l2_regularization=0.9734843059189102, gb__learning_rate=0.17559678733876366, gb__max_depth=3, gb__max_leaf_nodes=36, gb__min_samples_leaf=39; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=0.9734843059189102, gb__learning_rate=0.17559678733876366, gb__max_depth=3, gb__max_leaf_nodes=36, gb__min_samples_leaf=39; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=0.735431606118867, gb__learning_rate=0.004538772572503257, gb__max_depth=7, gb__max_leaf_nodes=245, gb__min_samples_leaf=118; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.9734843059189102, gb__learning_rate=0.17559678733876366, gb__max_depth=3, gb__max_leaf_nodes=36, gb__min_samples_leaf=39; total time=   1.1s\n",
      "[CV] END gb__l2_regularization=0.735431606118867, gb__learning_rate=0.004538772572503257, gb__max_depth=7, gb__max_leaf_nodes=245, gb__min_samples_leaf=118; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=0.735431606118867, gb__learning_rate=0.004538772572503257, gb__max_depth=7, gb__max_leaf_nodes=245, gb__min_samples_leaf=118; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.735431606118867, gb__learning_rate=0.004538772572503257, gb__max_depth=7, gb__max_leaf_nodes=245, gb__min_samples_leaf=118; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.735431606118867, gb__learning_rate=0.004538772572503257, gb__max_depth=7, gb__max_leaf_nodes=245, gb__min_samples_leaf=118; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.2902067240611297, gb__learning_rate=0.045394789438438554, gb__max_depth=2, gb__max_leaf_nodes=212, gb__min_samples_leaf=70; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.2902067240611297, gb__learning_rate=0.045394789438438554, gb__max_depth=2, gb__max_leaf_nodes=212, gb__min_samples_leaf=70; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.2902067240611297, gb__learning_rate=0.045394789438438554, gb__max_depth=2, gb__max_leaf_nodes=212, gb__min_samples_leaf=70; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.2902067240611297, gb__learning_rate=0.045394789438438554, gb__max_depth=2, gb__max_leaf_nodes=212, gb__min_samples_leaf=70; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.2902067240611297, gb__learning_rate=0.045394789438438554, gb__max_depth=2, gb__max_leaf_nodes=212, gb__min_samples_leaf=70; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.9983867597695046, gb__learning_rate=0.026117028299998492, gb__max_depth=2, gb__max_leaf_nodes=32, gb__min_samples_leaf=181; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.9983867597695046, gb__learning_rate=0.026117028299998492, gb__max_depth=2, gb__max_leaf_nodes=32, gb__min_samples_leaf=181; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.9983867597695046, gb__learning_rate=0.026117028299998492, gb__max_depth=2, gb__max_leaf_nodes=32, gb__min_samples_leaf=181; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.9983867597695046, gb__learning_rate=0.026117028299998492, gb__max_depth=2, gb__max_leaf_nodes=32, gb__min_samples_leaf=181; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.8809171687058286, gb__learning_rate=0.23067299454713366, gb__max_depth=6, gb__max_leaf_nodes=21, gb__min_samples_leaf=108; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=0.9983867597695046, gb__learning_rate=0.026117028299998492, gb__max_depth=2, gb__max_leaf_nodes=32, gb__min_samples_leaf=181; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.8809171687058286, gb__learning_rate=0.23067299454713366, gb__max_depth=6, gb__max_leaf_nodes=21, gb__min_samples_leaf=108; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.8809171687058286, gb__learning_rate=0.23067299454713366, gb__max_depth=6, gb__max_leaf_nodes=21, gb__min_samples_leaf=108; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.8809171687058286, gb__learning_rate=0.23067299454713366, gb__max_depth=6, gb__max_leaf_nodes=21, gb__min_samples_leaf=108; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.8809171687058286, gb__learning_rate=0.23067299454713366, gb__max_depth=6, gb__max_leaf_nodes=21, gb__min_samples_leaf=108; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.1445849383416766, gb__learning_rate=0.2681638318347544, gb__max_depth=5, gb__max_leaf_nodes=206, gb__min_samples_leaf=169; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=1.1445849383416766, gb__learning_rate=0.2681638318347544, gb__max_depth=5, gb__max_leaf_nodes=206, gb__min_samples_leaf=169; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.4954375477948278, gb__learning_rate=0.2295485371853974, gb__max_depth=2, gb__max_leaf_nodes=61, gb__min_samples_leaf=190; total time=   1.0s\n",
      "[CV] END gb__l2_regularization=1.1445849383416766, gb__learning_rate=0.2681638318347544, gb__max_depth=5, gb__max_leaf_nodes=206, gb__min_samples_leaf=169; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.4954375477948278, gb__learning_rate=0.2295485371853974, gb__max_depth=2, gb__max_leaf_nodes=61, gb__min_samples_leaf=190; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=1.4954375477948278, gb__learning_rate=0.2295485371853974, gb__max_depth=2, gb__max_leaf_nodes=61, gb__min_samples_leaf=190; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.4954375477948278, gb__learning_rate=0.2295485371853974, gb__max_depth=2, gb__max_leaf_nodes=61, gb__min_samples_leaf=190; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.1445849383416766, gb__learning_rate=0.2681638318347544, gb__max_depth=5, gb__max_leaf_nodes=206, gb__min_samples_leaf=169; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=1.4954375477948278, gb__learning_rate=0.2295485371853974, gb__max_depth=2, gb__max_leaf_nodes=61, gb__min_samples_leaf=190; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.1445849383416766, gb__learning_rate=0.2681638318347544, gb__max_depth=5, gb__max_leaf_nodes=206, gb__min_samples_leaf=169; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.7022733430337138, gb__learning_rate=0.006096130214748381, gb__max_depth=3, gb__max_leaf_nodes=40, gb__min_samples_leaf=63; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.7022733430337138, gb__learning_rate=0.006096130214748381, gb__max_depth=3, gb__max_leaf_nodes=40, gb__min_samples_leaf=63; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.7022733430337138, gb__learning_rate=0.006096130214748381, gb__max_depth=3, gb__max_leaf_nodes=40, gb__min_samples_leaf=63; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.7022733430337138, gb__learning_rate=0.006096130214748381, gb__max_depth=3, gb__max_leaf_nodes=40, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.7022733430337138, gb__learning_rate=0.006096130214748381, gb__max_depth=3, gb__max_leaf_nodes=40, gb__min_samples_leaf=63; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.392059593349946, gb__learning_rate=0.025829181313817826, gb__max_depth=9, gb__max_leaf_nodes=129, gb__min_samples_leaf=41; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.392059593349946, gb__learning_rate=0.025829181313817826, gb__max_depth=9, gb__max_leaf_nodes=129, gb__min_samples_leaf=41; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=1.392059593349946, gb__learning_rate=0.025829181313817826, gb__max_depth=9, gb__max_leaf_nodes=129, gb__min_samples_leaf=41; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=1.3422870336481012, gb__learning_rate=0.007734131730970359, gb__max_depth=3, gb__max_leaf_nodes=233, gb__min_samples_leaf=26; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3422870336481012, gb__learning_rate=0.007734131730970359, gb__max_depth=3, gb__max_leaf_nodes=233, gb__min_samples_leaf=26; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3422870336481012, gb__learning_rate=0.007734131730970359, gb__max_depth=3, gb__max_leaf_nodes=233, gb__min_samples_leaf=26; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.392059593349946, gb__learning_rate=0.025829181313817826, gb__max_depth=9, gb__max_leaf_nodes=129, gb__min_samples_leaf=41; total time=   2.6s\n",
      "[CV] END gb__l2_regularization=1.3422870336481012, gb__learning_rate=0.007734131730970359, gb__max_depth=3, gb__max_leaf_nodes=233, gb__min_samples_leaf=26; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.392059593349946, gb__learning_rate=0.025829181313817826, gb__max_depth=9, gb__max_leaf_nodes=129, gb__min_samples_leaf=41; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=1.3422870336481012, gb__learning_rate=0.007734131730970359, gb__max_depth=3, gb__max_leaf_nodes=233, gb__min_samples_leaf=26; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.5871836885289867, gb__learning_rate=0.10113133051262838, gb__max_depth=4, gb__max_leaf_nodes=65, gb__min_samples_leaf=162; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.5871836885289867, gb__learning_rate=0.10113133051262838, gb__max_depth=4, gb__max_leaf_nodes=65, gb__min_samples_leaf=162; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.5871836885289867, gb__learning_rate=0.10113133051262838, gb__max_depth=4, gb__max_leaf_nodes=65, gb__min_samples_leaf=162; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.6973395898493489, gb__learning_rate=0.0021798549893532583, gb__max_depth=7, gb__max_leaf_nodes=191, gb__min_samples_leaf=48; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=1.6973395898493489, gb__learning_rate=0.0021798549893532583, gb__max_depth=7, gb__max_leaf_nodes=191, gb__min_samples_leaf=48; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=1.6973395898493489, gb__learning_rate=0.0021798549893532583, gb__max_depth=7, gb__max_leaf_nodes=191, gb__min_samples_leaf=48; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.6973395898493489, gb__learning_rate=0.0021798549893532583, gb__max_depth=7, gb__max_leaf_nodes=191, gb__min_samples_leaf=48; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.5871836885289867, gb__learning_rate=0.10113133051262838, gb__max_depth=4, gb__max_leaf_nodes=65, gb__min_samples_leaf=162; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.6973395898493489, gb__learning_rate=0.0021798549893532583, gb__max_depth=7, gb__max_leaf_nodes=191, gb__min_samples_leaf=48; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.5871836885289867, gb__learning_rate=0.10113133051262838, gb__max_depth=4, gb__max_leaf_nodes=65, gb__min_samples_leaf=162; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.5965903579335503, gb__learning_rate=0.04074173013132515, gb__max_depth=4, gb__max_leaf_nodes=230, gb__min_samples_leaf=152; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.5965903579335503, gb__learning_rate=0.04074173013132515, gb__max_depth=4, gb__max_leaf_nodes=230, gb__min_samples_leaf=152; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.5965903579335503, gb__learning_rate=0.04074173013132515, gb__max_depth=4, gb__max_leaf_nodes=230, gb__min_samples_leaf=152; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.223027421731361, gb__learning_rate=0.0015926438852703654, gb__max_depth=8, gb__max_leaf_nodes=72, gb__min_samples_leaf=45; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=1.223027421731361, gb__learning_rate=0.0015926438852703654, gb__max_depth=8, gb__max_leaf_nodes=72, gb__min_samples_leaf=45; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.223027421731361, gb__learning_rate=0.0015926438852703654, gb__max_depth=8, gb__max_leaf_nodes=72, gb__min_samples_leaf=45; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.223027421731361, gb__learning_rate=0.0015926438852703654, gb__max_depth=8, gb__max_leaf_nodes=72, gb__min_samples_leaf=45; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=1.5965903579335503, gb__learning_rate=0.04074173013132515, gb__max_depth=4, gb__max_leaf_nodes=230, gb__min_samples_leaf=152; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.223027421731361, gb__learning_rate=0.0015926438852703654, gb__max_depth=8, gb__max_leaf_nodes=72, gb__min_samples_leaf=45; total time=   4.0s\n",
      "[CV] END gb__l2_regularization=1.5965903579335503, gb__learning_rate=0.04074173013132515, gb__max_depth=4, gb__max_leaf_nodes=230, gb__min_samples_leaf=152; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=0.751165905279888, gb__learning_rate=0.0017092463483395972, gb__max_depth=8, gb__max_leaf_nodes=206, gb__min_samples_leaf=95; total time=   3.7s\n",
      "[CV] END gb__l2_regularization=0.751165905279888, gb__learning_rate=0.0017092463483395972, gb__max_depth=8, gb__max_leaf_nodes=206, gb__min_samples_leaf=95; total time=   3.8s\n",
      "[CV] END gb__l2_regularization=0.6563053349494639, gb__learning_rate=0.002421346175400709, gb__max_depth=7, gb__max_leaf_nodes=73, gb__min_samples_leaf=67; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.751165905279888, gb__learning_rate=0.0017092463483395972, gb__max_depth=8, gb__max_leaf_nodes=206, gb__min_samples_leaf=95; total time=   3.7s\n",
      "[CV] END gb__l2_regularization=0.6563053349494639, gb__learning_rate=0.002421346175400709, gb__max_depth=7, gb__max_leaf_nodes=73, gb__min_samples_leaf=67; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.6563053349494639, gb__learning_rate=0.002421346175400709, gb__max_depth=7, gb__max_leaf_nodes=73, gb__min_samples_leaf=67; total time=   3.6s\n",
      "[CV] END gb__l2_regularization=0.751165905279888, gb__learning_rate=0.0017092463483395972, gb__max_depth=8, gb__max_leaf_nodes=206, gb__min_samples_leaf=95; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=0.751165905279888, gb__learning_rate=0.0017092463483395972, gb__max_depth=8, gb__max_leaf_nodes=206, gb__min_samples_leaf=95; total time=   3.8s\n",
      "[CV] END gb__l2_regularization=0.6563053349494639, gb__learning_rate=0.002421346175400709, gb__max_depth=7, gb__max_leaf_nodes=73, gb__min_samples_leaf=67; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.6563053349494639, gb__learning_rate=0.002421346175400709, gb__max_depth=7, gb__max_leaf_nodes=73, gb__min_samples_leaf=67; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.06100049987809886, gb__learning_rate=0.0012374167549216975, gb__max_depth=7, gb__max_leaf_nodes=30, gb__min_samples_leaf=63; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=0.06100049987809886, gb__learning_rate=0.0012374167549216975, gb__max_depth=7, gb__max_leaf_nodes=30, gb__min_samples_leaf=63; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=0.06100049987809886, gb__learning_rate=0.0012374167549216975, gb__max_depth=7, gb__max_leaf_nodes=30, gb__min_samples_leaf=63; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=0.06100049987809886, gb__learning_rate=0.0012374167549216975, gb__max_depth=7, gb__max_leaf_nodes=30, gb__min_samples_leaf=63; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=0.06100049987809886, gb__learning_rate=0.0012374167549216975, gb__max_depth=7, gb__max_leaf_nodes=30, gb__min_samples_leaf=63; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.0741648543933109, gb__learning_rate=0.006443988162165167, gb__max_depth=9, gb__max_leaf_nodes=68, gb__min_samples_leaf=69; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=0.43164205499368635, gb__learning_rate=0.03491204084552832, gb__max_depth=5, gb__max_leaf_nodes=21, gb__min_samples_leaf=118; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.43164205499368635, gb__learning_rate=0.03491204084552832, gb__max_depth=5, gb__max_leaf_nodes=21, gb__min_samples_leaf=118; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.43164205499368635, gb__learning_rate=0.03491204084552832, gb__max_depth=5, gb__max_leaf_nodes=21, gb__min_samples_leaf=118; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.0741648543933109, gb__learning_rate=0.006443988162165167, gb__max_depth=9, gb__max_leaf_nodes=68, gb__min_samples_leaf=69; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=1.0741648543933109, gb__learning_rate=0.006443988162165167, gb__max_depth=9, gb__max_leaf_nodes=68, gb__min_samples_leaf=69; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=0.43164205499368635, gb__learning_rate=0.03491204084552832, gb__max_depth=5, gb__max_leaf_nodes=21, gb__min_samples_leaf=118; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.0741648543933109, gb__learning_rate=0.006443988162165167, gb__max_depth=9, gb__max_leaf_nodes=68, gb__min_samples_leaf=69; total time=   3.9s\n",
      "[CV] END gb__l2_regularization=1.0741648543933109, gb__learning_rate=0.006443988162165167, gb__max_depth=9, gb__max_leaf_nodes=68, gb__min_samples_leaf=69; total time=   4.1s\n",
      "[CV] END gb__l2_regularization=0.43164205499368635, gb__learning_rate=0.03491204084552832, gb__max_depth=5, gb__max_leaf_nodes=21, gb__min_samples_leaf=118; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.452182667445323, gb__learning_rate=0.2613990034157314, gb__max_depth=4, gb__max_leaf_nodes=160, gb__min_samples_leaf=129; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=0.38876006798974605, gb__learning_rate=0.01044656477334282, gb__max_depth=4, gb__max_leaf_nodes=70, gb__min_samples_leaf=177; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.38876006798974605, gb__learning_rate=0.01044656477334282, gb__max_depth=4, gb__max_leaf_nodes=70, gb__min_samples_leaf=177; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.452182667445323, gb__learning_rate=0.2613990034157314, gb__max_depth=4, gb__max_leaf_nodes=160, gb__min_samples_leaf=129; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.452182667445323, gb__learning_rate=0.2613990034157314, gb__max_depth=4, gb__max_leaf_nodes=160, gb__min_samples_leaf=129; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=1.452182667445323, gb__learning_rate=0.2613990034157314, gb__max_depth=4, gb__max_leaf_nodes=160, gb__min_samples_leaf=129; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.38876006798974605, gb__learning_rate=0.01044656477334282, gb__max_depth=4, gb__max_leaf_nodes=70, gb__min_samples_leaf=177; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.452182667445323, gb__learning_rate=0.2613990034157314, gb__max_depth=4, gb__max_leaf_nodes=160, gb__min_samples_leaf=129; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=0.38876006798974605, gb__learning_rate=0.01044656477334282, gb__max_depth=4, gb__max_leaf_nodes=70, gb__min_samples_leaf=177; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.38876006798974605, gb__learning_rate=0.01044656477334282, gb__max_depth=4, gb__max_leaf_nodes=70, gb__min_samples_leaf=177; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.5416645025241484, gb__learning_rate=0.012228844889430076, gb__max_depth=8, gb__max_leaf_nodes=105, gb__min_samples_leaf=126; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=0.5416645025241484, gb__learning_rate=0.012228844889430076, gb__max_depth=8, gb__max_leaf_nodes=105, gb__min_samples_leaf=126; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=0.16174593323439534, gb__learning_rate=0.011507656492657838, gb__max_depth=6, gb__max_leaf_nodes=144, gb__min_samples_leaf=67; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.16174593323439534, gb__learning_rate=0.011507656492657838, gb__max_depth=6, gb__max_leaf_nodes=144, gb__min_samples_leaf=67; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=0.5416645025241484, gb__learning_rate=0.012228844889430076, gb__max_depth=8, gb__max_leaf_nodes=105, gb__min_samples_leaf=126; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=0.5416645025241484, gb__learning_rate=0.012228844889430076, gb__max_depth=8, gb__max_leaf_nodes=105, gb__min_samples_leaf=126; total time=   3.0s\n",
      "[CV] END gb__l2_regularization=0.5416645025241484, gb__learning_rate=0.012228844889430076, gb__max_depth=8, gb__max_leaf_nodes=105, gb__min_samples_leaf=126; total time=   3.1s\n",
      "[CV] END gb__l2_regularization=0.16174593323439534, gb__learning_rate=0.011507656492657838, gb__max_depth=6, gb__max_leaf_nodes=144, gb__min_samples_leaf=67; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=0.16174593323439534, gb__learning_rate=0.011507656492657838, gb__max_depth=6, gb__max_leaf_nodes=144, gb__min_samples_leaf=67; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=0.16174593323439534, gb__learning_rate=0.011507656492657838, gb__max_depth=6, gb__max_leaf_nodes=144, gb__min_samples_leaf=67; total time=   2.7s\n",
      "[CV] END gb__l2_regularization=1.830427455252961, gb__learning_rate=0.01246694691815194, gb__max_depth=7, gb__max_leaf_nodes=63, gb__min_samples_leaf=98; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=1.830427455252961, gb__learning_rate=0.01246694691815194, gb__max_depth=7, gb__max_leaf_nodes=63, gb__min_samples_leaf=98; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=1.830427455252961, gb__learning_rate=0.01246694691815194, gb__max_depth=7, gb__max_leaf_nodes=63, gb__min_samples_leaf=98; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=1.830427455252961, gb__learning_rate=0.01246694691815194, gb__max_depth=7, gb__max_leaf_nodes=63, gb__min_samples_leaf=98; total time=   2.8s\n",
      "[CV] END gb__l2_regularization=1.830427455252961, gb__learning_rate=0.01246694691815194, gb__max_depth=7, gb__max_leaf_nodes=63, gb__min_samples_leaf=98; total time=   2.9s\n",
      "[CV] END gb__l2_regularization=1.3203947534354625, gb__learning_rate=0.00493662577075327, gb__max_depth=8, gb__max_leaf_nodes=207, gb__min_samples_leaf=200; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=0.8713457973557821, gb__learning_rate=0.06432738659488216, gb__max_depth=4, gb__max_leaf_nodes=91, gb__min_samples_leaf=163; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.8713457973557821, gb__learning_rate=0.06432738659488216, gb__max_depth=4, gb__max_leaf_nodes=91, gb__min_samples_leaf=163; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.8713457973557821, gb__learning_rate=0.06432738659488216, gb__max_depth=4, gb__max_leaf_nodes=91, gb__min_samples_leaf=163; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.8713457973557821, gb__learning_rate=0.06432738659488216, gb__max_depth=4, gb__max_leaf_nodes=91, gb__min_samples_leaf=163; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3203947534354625, gb__learning_rate=0.00493662577075327, gb__max_depth=8, gb__max_leaf_nodes=207, gb__min_samples_leaf=200; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.3203947534354625, gb__learning_rate=0.00493662577075327, gb__max_depth=8, gb__max_leaf_nodes=207, gb__min_samples_leaf=200; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.7119453573025232, gb__learning_rate=0.07538357125084306, gb__max_depth=10, gb__max_leaf_nodes=44, gb__min_samples_leaf=78; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=1.3203947534354625, gb__learning_rate=0.00493662577075327, gb__max_depth=8, gb__max_leaf_nodes=207, gb__min_samples_leaf=200; total time=   3.5s\n",
      "[CV] END gb__l2_regularization=1.3203947534354625, gb__learning_rate=0.00493662577075327, gb__max_depth=8, gb__max_leaf_nodes=207, gb__min_samples_leaf=200; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.7119453573025232, gb__learning_rate=0.07538357125084306, gb__max_depth=10, gb__max_leaf_nodes=44, gb__min_samples_leaf=78; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.8713457973557821, gb__learning_rate=0.06432738659488216, gb__max_depth=4, gb__max_leaf_nodes=91, gb__min_samples_leaf=163; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=0.7119453573025232, gb__learning_rate=0.07538357125084306, gb__max_depth=10, gb__max_leaf_nodes=44, gb__min_samples_leaf=78; total time=   1.3s\n",
      "[CV] END gb__l2_regularization=0.7119453573025232, gb__learning_rate=0.07538357125084306, gb__max_depth=10, gb__max_leaf_nodes=44, gb__min_samples_leaf=78; total time=   1.0s\n",
      "[CV] END gb__l2_regularization=0.7119453573025232, gb__learning_rate=0.07538357125084306, gb__max_depth=10, gb__max_leaf_nodes=44, gb__min_samples_leaf=78; total time=   1.2s\n",
      "[CV] END gb__l2_regularization=0.18831397653712023, gb__learning_rate=0.005907565256979222, gb__max_depth=5, gb__max_leaf_nodes=212, gb__min_samples_leaf=153; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.18831397653712023, gb__learning_rate=0.005907565256979222, gb__max_depth=5, gb__max_leaf_nodes=212, gb__min_samples_leaf=153; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.18831397653712023, gb__learning_rate=0.005907565256979222, gb__max_depth=5, gb__max_leaf_nodes=212, gb__min_samples_leaf=153; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.18831397653712023, gb__learning_rate=0.005907565256979222, gb__max_depth=5, gb__max_leaf_nodes=212, gb__min_samples_leaf=153; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.18831397653712023, gb__learning_rate=0.005907565256979222, gb__max_depth=5, gb__max_leaf_nodes=212, gb__min_samples_leaf=153; total time=   2.5s\n",
      "[CV] END gb__l2_regularization=0.19566832130200296, gb__learning_rate=0.016511713080981927, gb__max_depth=8, gb__max_leaf_nodes=115, gb__min_samples_leaf=42; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=0.19566832130200296, gb__learning_rate=0.016511713080981927, gb__max_depth=8, gb__max_leaf_nodes=115, gb__min_samples_leaf=42; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.19566832130200296, gb__learning_rate=0.016511713080981927, gb__max_depth=8, gb__max_leaf_nodes=115, gb__min_samples_leaf=42; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.9293476258792228, gb__learning_rate=0.040697543873967026, gb__max_depth=7, gb__max_leaf_nodes=84, gb__min_samples_leaf=109; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=0.9293476258792228, gb__learning_rate=0.040697543873967026, gb__max_depth=7, gb__max_leaf_nodes=84, gb__min_samples_leaf=109; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=0.9293476258792228, gb__learning_rate=0.040697543873967026, gb__max_depth=7, gb__max_leaf_nodes=84, gb__min_samples_leaf=109; total time=   2.4s\n",
      "[CV] END gb__l2_regularization=0.19566832130200296, gb__learning_rate=0.016511713080981927, gb__max_depth=8, gb__max_leaf_nodes=115, gb__min_samples_leaf=42; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.19566832130200296, gb__learning_rate=0.016511713080981927, gb__max_depth=8, gb__max_leaf_nodes=115, gb__min_samples_leaf=42; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.9293476258792228, gb__learning_rate=0.040697543873967026, gb__max_depth=7, gb__max_leaf_nodes=84, gb__min_samples_leaf=109; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.09060801954408904, gb__learning_rate=0.008471510822141294, gb__max_depth=4, gb__max_leaf_nodes=201, gb__min_samples_leaf=105; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.9293476258792228, gb__learning_rate=0.040697543873967026, gb__max_depth=7, gb__max_leaf_nodes=84, gb__min_samples_leaf=109; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=0.09060801954408904, gb__learning_rate=0.008471510822141294, gb__max_depth=4, gb__max_leaf_nodes=201, gb__min_samples_leaf=105; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.09060801954408904, gb__learning_rate=0.008471510822141294, gb__max_depth=4, gb__max_leaf_nodes=201, gb__min_samples_leaf=105; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.09060801954408904, gb__learning_rate=0.008471510822141294, gb__max_depth=4, gb__max_leaf_nodes=201, gb__min_samples_leaf=105; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.7129796823766446, gb__learning_rate=0.04282170893894739, gb__max_depth=5, gb__max_leaf_nodes=31, gb__min_samples_leaf=33; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.7129796823766446, gb__learning_rate=0.04282170893894739, gb__max_depth=5, gb__max_leaf_nodes=31, gb__min_samples_leaf=33; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.09060801954408904, gb__learning_rate=0.008471510822141294, gb__max_depth=4, gb__max_leaf_nodes=201, gb__min_samples_leaf=105; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=1.7129796823766446, gb__learning_rate=0.04282170893894739, gb__max_depth=5, gb__max_leaf_nodes=31, gb__min_samples_leaf=33; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.8877832091215143, gb__learning_rate=0.21828590870797615, gb__max_depth=5, gb__max_leaf_nodes=167, gb__min_samples_leaf=149; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=1.7129796823766446, gb__learning_rate=0.04282170893894739, gb__max_depth=5, gb__max_leaf_nodes=31, gb__min_samples_leaf=33; total time=   2.3s\n",
      "[CV] END gb__l2_regularization=1.8877832091215143, gb__learning_rate=0.21828590870797615, gb__max_depth=5, gb__max_leaf_nodes=167, gb__min_samples_leaf=149; total time=   0.9s\n",
      "[CV] END gb__l2_regularization=1.8877832091215143, gb__learning_rate=0.21828590870797615, gb__max_depth=5, gb__max_leaf_nodes=167, gb__min_samples_leaf=149; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.8877832091215143, gb__learning_rate=0.21828590870797615, gb__max_depth=5, gb__max_leaf_nodes=167, gb__min_samples_leaf=149; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.8877832091215143, gb__learning_rate=0.21828590870797615, gb__max_depth=5, gb__max_leaf_nodes=167, gb__min_samples_leaf=149; total time=   0.8s\n",
      "[CV] END gb__l2_regularization=1.7129796823766446, gb__learning_rate=0.04282170893894739, gb__max_depth=5, gb__max_leaf_nodes=31, gb__min_samples_leaf=33; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.7763398524130438, gb__learning_rate=0.03921957822003797, gb__max_depth=2, gb__max_leaf_nodes=204, gb__min_samples_leaf=188; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.7763398524130438, gb__learning_rate=0.03921957822003797, gb__max_depth=2, gb__max_leaf_nodes=204, gb__min_samples_leaf=188; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.7763398524130438, gb__learning_rate=0.03921957822003797, gb__max_depth=2, gb__max_leaf_nodes=204, gb__min_samples_leaf=188; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=0.7763398524130438, gb__learning_rate=0.03921957822003797, gb__max_depth=2, gb__max_leaf_nodes=204, gb__min_samples_leaf=188; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.6412789514879107, gb__learning_rate=0.03552453983111037, gb__max_depth=2, gb__max_leaf_nodes=176, gb__min_samples_leaf=177; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.7763398524130438, gb__learning_rate=0.03921957822003797, gb__max_depth=2, gb__max_leaf_nodes=204, gb__min_samples_leaf=188; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.6412789514879107, gb__learning_rate=0.03552453983111037, gb__max_depth=2, gb__max_leaf_nodes=176, gb__min_samples_leaf=177; total time=   1.4s\n",
      "[CV] END gb__l2_regularization=1.6412789514879107, gb__learning_rate=0.03552453983111037, gb__max_depth=2, gb__max_leaf_nodes=176, gb__min_samples_leaf=177; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.6412789514879107, gb__learning_rate=0.03552453983111037, gb__max_depth=2, gb__max_leaf_nodes=176, gb__min_samples_leaf=177; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.6412789514879107, gb__learning_rate=0.03552453983111037, gb__max_depth=2, gb__max_leaf_nodes=176, gb__min_samples_leaf=177; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.8107012839121275, gb__learning_rate=0.0030549097281632213, gb__max_depth=3, gb__max_leaf_nodes=50, gb__min_samples_leaf=90; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.8107012839121275, gb__learning_rate=0.0030549097281632213, gb__max_depth=3, gb__max_leaf_nodes=50, gb__min_samples_leaf=90; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.8107012839121275, gb__learning_rate=0.0030549097281632213, gb__max_depth=3, gb__max_leaf_nodes=50, gb__min_samples_leaf=90; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.8107012839121275, gb__learning_rate=0.0030549097281632213, gb__max_depth=3, gb__max_leaf_nodes=50, gb__min_samples_leaf=90; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=1.8107012839121275, gb__learning_rate=0.0030549097281632213, gb__max_depth=3, gb__max_leaf_nodes=50, gb__min_samples_leaf=90; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3114452707614843, gb__learning_rate=0.009008949682945841, gb__max_depth=3, gb__max_leaf_nodes=130, gb__min_samples_leaf=114; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3114452707614843, gb__learning_rate=0.009008949682945841, gb__max_depth=3, gb__max_leaf_nodes=130, gb__min_samples_leaf=114; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.3114452707614843, gb__learning_rate=0.009008949682945841, gb__max_depth=3, gb__max_leaf_nodes=130, gb__min_samples_leaf=114; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3114452707614843, gb__learning_rate=0.009008949682945841, gb__max_depth=3, gb__max_leaf_nodes=130, gb__min_samples_leaf=114; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=1.3114452707614843, gb__learning_rate=0.009008949682945841, gb__max_depth=3, gb__max_leaf_nodes=130, gb__min_samples_leaf=114; total time=   1.8s\n",
      "[CV] END gb__l2_regularization=0.9920749085868124, gb__learning_rate=0.052044331527794765, gb__max_depth=3, gb__max_leaf_nodes=252, gb__min_samples_leaf=84; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.9920749085868124, gb__learning_rate=0.052044331527794765, gb__max_depth=3, gb__max_leaf_nodes=252, gb__min_samples_leaf=84; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.9920749085868124, gb__learning_rate=0.052044331527794765, gb__max_depth=3, gb__max_leaf_nodes=252, gb__min_samples_leaf=84; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.9920749085868124, gb__learning_rate=0.052044331527794765, gb__max_depth=3, gb__max_leaf_nodes=252, gb__min_samples_leaf=84; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=0.9920749085868124, gb__learning_rate=0.052044331527794765, gb__max_depth=3, gb__max_leaf_nodes=252, gb__min_samples_leaf=84; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.754944027054106, gb__learning_rate=0.06620032268162324, gb__max_depth=6, gb__max_leaf_nodes=179, gb__min_samples_leaf=147; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.754944027054106, gb__learning_rate=0.06620032268162324, gb__max_depth=6, gb__max_leaf_nodes=179, gb__min_samples_leaf=147; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.754944027054106, gb__learning_rate=0.06620032268162324, gb__max_depth=6, gb__max_leaf_nodes=179, gb__min_samples_leaf=147; total time=   1.7s\n",
      "[CV] END gb__l2_regularization=1.754944027054106, gb__learning_rate=0.06620032268162324, gb__max_depth=6, gb__max_leaf_nodes=179, gb__min_samples_leaf=147; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.754944027054106, gb__learning_rate=0.06620032268162324, gb__max_depth=6, gb__max_leaf_nodes=179, gb__min_samples_leaf=147; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.8469418846162371, gb__learning_rate=0.02560316638982875, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=108; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.8469418846162371, gb__learning_rate=0.02560316638982875, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=108; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.8469418846162371, gb__learning_rate=0.02560316638982875, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=108; total time=   1.9s\n",
      "[CV] END gb__l2_regularization=0.8469418846162371, gb__learning_rate=0.02560316638982875, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=108; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=0.8469418846162371, gb__learning_rate=0.02560316638982875, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=108; total time=   2.0s\n",
      "[CV] END gb__l2_regularization=1.7342332144194441, gb__learning_rate=0.024649716311043752, gb__max_depth=2, gb__max_leaf_nodes=198, gb__min_samples_leaf=22; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.825235353822853, gb__learning_rate=0.008347067152982127, gb__max_depth=8, gb__max_leaf_nodes=111, gb__min_samples_leaf=161; total time=   3.2s\n",
      "[CV] END gb__l2_regularization=1.7342332144194441, gb__learning_rate=0.024649716311043752, gb__max_depth=2, gb__max_leaf_nodes=198, gb__min_samples_leaf=22; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.7342332144194441, gb__learning_rate=0.024649716311043752, gb__max_depth=2, gb__max_leaf_nodes=198, gb__min_samples_leaf=22; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=0.825235353822853, gb__learning_rate=0.008347067152982127, gb__max_depth=8, gb__max_leaf_nodes=111, gb__min_samples_leaf=161; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=0.825235353822853, gb__learning_rate=0.008347067152982127, gb__max_depth=8, gb__max_leaf_nodes=111, gb__min_samples_leaf=161; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.825235353822853, gb__learning_rate=0.008347067152982127, gb__max_depth=8, gb__max_leaf_nodes=111, gb__min_samples_leaf=161; total time=   3.4s\n",
      "[CV] END gb__l2_regularization=0.825235353822853, gb__learning_rate=0.008347067152982127, gb__max_depth=8, gb__max_leaf_nodes=111, gb__min_samples_leaf=161; total time=   3.3s\n",
      "[CV] END gb__l2_regularization=1.7342332144194441, gb__learning_rate=0.024649716311043752, gb__max_depth=2, gb__max_leaf_nodes=198, gb__min_samples_leaf=22; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.7342332144194441, gb__learning_rate=0.024649716311043752, gb__max_depth=2, gb__max_leaf_nodes=198, gb__min_samples_leaf=22; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.479817520894749, gb__learning_rate=0.003891704322710823, gb__max_depth=2, gb__max_leaf_nodes=128, gb__min_samples_leaf=71; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.479817520894749, gb__learning_rate=0.003891704322710823, gb__max_depth=2, gb__max_leaf_nodes=128, gb__min_samples_leaf=71; total time=   1.5s\n",
      "[CV] END gb__l2_regularization=1.479817520894749, gb__learning_rate=0.003891704322710823, gb__max_depth=2, gb__max_leaf_nodes=128, gb__min_samples_leaf=71; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.479817520894749, gb__learning_rate=0.003891704322710823, gb__max_depth=2, gb__max_leaf_nodes=128, gb__min_samples_leaf=71; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=1.479817520894749, gb__learning_rate=0.003891704322710823, gb__max_depth=2, gb__max_leaf_nodes=128, gb__min_samples_leaf=71; total time=   1.6s\n",
      "[CV] END gb__l2_regularization=0.02167530296059672, gb__learning_rate=0.17488031925099976, gb__max_depth=10, gb__max_leaf_nodes=214, gb__min_samples_leaf=37; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.02167530296059672, gb__learning_rate=0.17488031925099976, gb__max_depth=10, gb__max_leaf_nodes=214, gb__min_samples_leaf=37; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.02167530296059672, gb__learning_rate=0.17488031925099976, gb__max_depth=10, gb__max_leaf_nodes=214, gb__min_samples_leaf=37; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.9931223813661554, gb__learning_rate=0.009228502678304636, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=109; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.02167530296059672, gb__learning_rate=0.17488031925099976, gb__max_depth=10, gb__max_leaf_nodes=214, gb__min_samples_leaf=37; total time=   0.5s\n",
      "[CV] END gb__l2_regularization=0.9931223813661554, gb__learning_rate=0.009228502678304636, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=109; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=0.02167530296059672, gb__learning_rate=0.17488031925099976, gb__max_depth=10, gb__max_leaf_nodes=214, gb__min_samples_leaf=37; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=1.9001239341016098, gb__learning_rate=0.22634409485528373, gb__max_depth=4, gb__max_leaf_nodes=126, gb__min_samples_leaf=153; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=1.9001239341016098, gb__learning_rate=0.22634409485528373, gb__max_depth=4, gb__max_leaf_nodes=126, gb__min_samples_leaf=153; total time=   0.7s\n",
      "[CV] END gb__l2_regularization=0.9931223813661554, gb__learning_rate=0.009228502678304636, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=109; total time=   2.2s\n",
      "[CV] END gb__l2_regularization=0.9931223813661554, gb__learning_rate=0.009228502678304636, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=109; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.9001239341016098, gb__learning_rate=0.22634409485528373, gb__max_depth=4, gb__max_leaf_nodes=126, gb__min_samples_leaf=153; total time=   0.6s\n",
      "[CV] END gb__l2_regularization=0.9931223813661554, gb__learning_rate=0.009228502678304636, gb__max_depth=4, gb__max_leaf_nodes=192, gb__min_samples_leaf=109; total time=   2.1s\n",
      "[CV] END gb__l2_regularization=1.9001239341016098, gb__learning_rate=0.22634409485528373, gb__max_depth=4, gb__max_leaf_nodes=126, gb__min_samples_leaf=153; total time=   1.0s\n",
      "[CV] END gb__l2_regularization=1.9001239341016098, gb__learning_rate=0.22634409485528373, gb__max_depth=4, gb__max_leaf_nodes=126, gb__min_samples_leaf=153; total time=   0.6s\n",
      "Randomized search completed in 00:02:30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_leaf_nodes</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__min_samples_leaf</th>\n",
       "      <th>param_gb__l2_regularization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>1.829919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.711962</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.268164</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "      <td>1.144585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.157664</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>1.275115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.711045</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.229549</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>1.495438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.711026</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "      <td>1.689068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  param_gb__learning_rate  \\\n",
       "19         0.712000        0.003063                 0.127541   \n",
       "60         0.711962        0.004237                 0.268164   \n",
       "21         0.711405        0.003213                 0.157664   \n",
       "59         0.711045        0.003477                 0.229549   \n",
       "14         0.711026        0.002790                 0.070991   \n",
       "\n",
       "    param_gb__max_leaf_nodes  param_gb__max_depth  param_gb__min_samples_leaf  \\\n",
       "19                        48                    3                          57   \n",
       "60                       206                    5                         169   \n",
       "21                       242                    2                         110   \n",
       "59                        61                    2                         190   \n",
       "14                        39                    6                         163   \n",
       "\n",
       "    param_gb__l2_regularization  \n",
       "19                     1.829919  \n",
       "60                     1.144585  \n",
       "21                     1.275115  \n",
       "59                     1.495438  \n",
       "14                     1.689068  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "param_distributions = {\n",
    "    \"gb__learning_rate\":     loguniform(1e-3, 0.3),\n",
    "    \"gb__max_leaf_nodes\":    randint(16, 257),\n",
    "    \"gb__max_depth\":         randint(2, 11),\n",
    "    \"gb__min_samples_leaf\":  randint(10, 201),\n",
    "    \"gb__l2_regularization\": uniform(0.0, 2.0)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipelined_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100, \n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    random_state=random_seed,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Randomized search completed in {format_hms(end - start)}\")\n",
    "\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "top5 = results_df.sort_values(by=\"mean_test_score\", ascending=False).head(5)\n",
    "\n",
    "display(top5[[\n",
    "    \"mean_test_score\", \n",
    "    \"std_test_score\", \n",
    "    \"param_gb__learning_rate\", \n",
    "    \"param_gb__max_leaf_nodes\", \n",
    "    \"param_gb__max_depth\", \n",
    "    \"param_gb__min_samples_leaf\", \n",
    "    \"param_gb__l2_regularization\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    0.712000\n",
       "60    0.711962\n",
       "21    0.711405\n",
       "59    0.711045\n",
       "14    0.711026\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Graded Answer\n",
    "\n",
    "Set `a2` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a2 = random_search.best_score_                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.7120\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a2 = {a2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Optimization with Optuna for F1\n",
    "\n",
    "In this problem, you will explore **Optuna**, a powerful hyperparameter optimization framework, to identify the best combination of hyperparameters that maximize the F1 score of your `pipelined_model`.\n",
    "\n",
    "**Background:**\n",
    "Optuna uses a smarter sampling strategy than grid search or randomized search, allowing you to explore the hyperparameter space more efficiently. It also supports *pruning*, which can stop unpromising trials early to save time. This makes it a popular SOTA optimization tool.\n",
    "\n",
    "**Before you start** browse the [Optuna documentation](https://optuna.org) and view the [tutorial video](https://optuna.readthedocs.io/en/stable/tutorial/index.html). \n",
    "\n",
    "As before, we focus on the **F1 score** because it balances precision and recall, making it more robust on an imbalanced dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Define an Optuna objective function to optimize F1 score, sampling the exact same hyperparameter ranges you did in Problem 2 and using the same CV settings.  \n",
    "3. Set up an Optuna study with a reasonable number of trials (e.g., 100–500 depending on runtime resources--on my machine Optuna runs about 10x faster than randomized search for the same number of trials, but YMMV).\n",
    "4. After running the optimization, `display` a clean table with the top 5 trials showing their F1 scores and corresponding hyperparameter settings.\n",
    "5. Answer the graded question. \n",
    "\n",
    "**Note:**  There are many resources on Optuna you can find on the web, but for this problem, you have my permission to let ChatGPT write the code for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# CHatGPT wrote this because i sure can't\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 16, 256),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 200),\n",
    "        \"l2_regularization\": trial.suggest_float(\"l2_regularization\", 0.0, 2.0)\n",
    "    }\n",
    "\n",
    "    model = HistGradientBoostingClassifier(\n",
    "        **params,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        validation_fraction=0.2,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=random_seed,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"gb\", model)\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "    scores = cross_val_score(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:43,075] A new study created in memory with name: no-name-4c277376-2564-4762-b33b-cb6dd5b8d582\n",
      "Best trial: 0. Best value: 0.693294:   1%|          | 1/100 [00:04<07:50,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:47,828] Trial 0 finished with value: 0.6932940220816347 and parameters: {'learning_rate': 0.008468008575248327, 'max_leaf_nodes': 245, 'max_depth': 8, 'min_samples_leaf': 124, 'l2_regularization': 0.31203728088487304}. Best is trial 0 with value: 0.6932940220816347.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.693294:   2%|▏         | 2/100 [00:07<06:17,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:51,053] Trial 1 finished with value: 0.6757628077310386 and parameters: {'learning_rate': 0.0024345423962016913, 'max_leaf_nodes': 29, 'max_depth': 9, 'min_samples_leaf': 124, 'l2_regularization': 1.416145155592091}. Best is trial 0 with value: 0.6932940220816347.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.693294:   3%|▎         | 3/100 [00:12<06:41,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:55,535] Trial 2 finished with value: 0.6737028554087643 and parameters: {'learning_rate': 0.001124579825911934, 'max_leaf_nodes': 249, 'max_depth': 9, 'min_samples_leaf': 50, 'l2_regularization': 0.36364993441420124}. Best is trial 0 with value: 0.6932940220816347.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.693294:   4%|▍         | 4/100 [00:15<05:40,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:58,177] Trial 3 finished with value: 0.6702328589793822 and parameters: {'learning_rate': 0.002846526357761094, 'max_leaf_nodes': 89, 'max_depth': 6, 'min_samples_leaf': 92, 'l2_regularization': 0.5824582803960838}. Best is trial 0 with value: 0.6932940220816347.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.70723:   5%|▌         | 5/100 [00:16<04:34,  2.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:08:59,909] Trial 4 finished with value: 0.7072303165616105 and parameters: {'learning_rate': 0.032781876533976156, 'max_leaf_nodes': 49, 'max_depth': 4, 'min_samples_leaf': 79, 'l2_regularization': 0.9121399684340719}. Best is trial 4 with value: 0.7072303165616105.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:   6%|▌         | 6/100 [00:18<03:43,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:01,284] Trial 5 finished with value: 0.7106934565679892 and parameters: {'learning_rate': 0.08810003129071789, 'max_leaf_nodes': 64, 'max_depth': 6, 'min_samples_leaf': 123, 'l2_regularization': 0.09290082543999545}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:   7%|▋         | 7/100 [00:19<03:08,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:02,606] Trial 6 finished with value: 0.6924582687003562 and parameters: {'learning_rate': 0.03198617182203562, 'max_leaf_nodes': 57, 'max_depth': 2, 'min_samples_leaf': 191, 'l2_regularization': 1.9312640661491187}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:   8%|▊         | 8/100 [00:20<02:44,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:03,863] Trial 7 finished with value: 0.7077598934727538 and parameters: {'learning_rate': 0.10057690178153984, 'max_leaf_nodes': 89, 'max_depth': 2, 'min_samples_leaf': 140, 'l2_regularization': 0.8803049874792026}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:   9%|▉         | 9/100 [00:22<02:31,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:05,277] Trial 8 finished with value: 0.6158150355713565 and parameters: {'learning_rate': 0.002005873336344495, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 183, 'l2_regularization': 0.5175599632000338}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:  10%|█         | 10/100 [00:24<02:37,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:07,218] Trial 9 finished with value: 0.7086410872976341 and parameters: {'learning_rate': 0.043767126303409544, 'max_leaf_nodes': 91, 'max_depth': 6, 'min_samples_leaf': 114, 'l2_regularization': 0.3697089110510541}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.710693:  11%|█         | 11/100 [00:24<02:03,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:07,768] Trial 10 finished with value: 0.7104676818474536 and parameters: {'learning_rate': 0.2597765579460734, 'max_leaf_nodes': 184, 'max_depth': 4, 'min_samples_leaf': 13, 'l2_regularization': 0.029026933760103082}. Best is trial 5 with value: 0.7106934565679892.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.710754:  12%|█▏        | 12/100 [00:25<01:43,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:08,457] Trial 11 finished with value: 0.7107539429091101 and parameters: {'learning_rate': 0.20737688966099269, 'max_leaf_nodes': 190, 'max_depth': 4, 'min_samples_leaf': 26, 'l2_regularization': 0.007453247542965356}. Best is trial 11 with value: 0.7107539429091101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.710754:  13%|█▎        | 13/100 [00:25<01:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:08,934] Trial 12 finished with value: 0.7106322231626644 and parameters: {'learning_rate': 0.29164518997919237, 'max_leaf_nodes': 184, 'max_depth': 4, 'min_samples_leaf': 19, 'l2_regularization': 0.03287085363744248}. Best is trial 11 with value: 0.7107539429091101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.710754:  14%|█▍        | 14/100 [00:27<01:29,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:10,168] Trial 13 finished with value: 0.7089081479717275 and parameters: {'learning_rate': 0.10698574322618062, 'max_leaf_nodes': 179, 'max_depth': 7, 'min_samples_leaf': 159, 'l2_regularization': 1.291712881406482}. Best is trial 11 with value: 0.7107539429091101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.711461:  15%|█▌        | 15/100 [00:28<01:30,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:11,279] Trial 14 finished with value: 0.7114610518441437 and parameters: {'learning_rate': 0.10324708464927795, 'max_leaf_nodes': 143, 'max_depth': 5, 'min_samples_leaf': 62, 'l2_regularization': 0.029010502180317324}. Best is trial 14 with value: 0.7114610518441437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.711461:  16%|█▌        | 16/100 [00:30<01:56,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:13,416] Trial 15 finished with value: 0.6939877223673048 and parameters: {'learning_rate': 0.011156032326330684, 'max_leaf_nodes': 142, 'max_depth': 5, 'min_samples_leaf': 55, 'l2_regularization': 0.6181117074039463}. Best is trial 14 with value: 0.7114610518441437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  17%|█▋        | 17/100 [00:31<01:51,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:14,659] Trial 16 finished with value: 0.7118406276851876 and parameters: {'learning_rate': 0.14431593219072464, 'max_leaf_nodes': 148, 'max_depth': 3, 'min_samples_leaf': 46, 'l2_regularization': 1.9315698226294058}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  18%|█▊        | 18/100 [00:33<01:58,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:16,319] Trial 17 finished with value: 0.7086126653502429 and parameters: {'learning_rate': 0.05752354583381458, 'max_leaf_nodes': 139, 'max_depth': 3, 'min_samples_leaf': 48, 'l2_regularization': 1.9920339787224275}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  19%|█▉        | 19/100 [00:35<02:10,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:18,349] Trial 18 finished with value: 0.7002153544414533 and parameters: {'learning_rate': 0.016077326614463906, 'max_leaf_nodes': 217, 'max_depth': 5, 'min_samples_leaf': 73, 'l2_regularization': 1.640944506373384}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  20%|██        | 20/100 [00:36<01:58,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:19,535] Trial 19 finished with value: 0.7113532831368609 and parameters: {'learning_rate': 0.13300310865214512, 'max_leaf_nodes': 156, 'max_depth': 3, 'min_samples_leaf': 34, 'l2_regularization': 1.1692992893084941}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  21%|██        | 21/100 [00:40<02:47,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:23,120] Trial 20 finished with value: 0.6901945521572845 and parameters: {'learning_rate': 0.006220974659612621, 'max_leaf_nodes': 114, 'max_depth': 10, 'min_samples_leaf': 70, 'l2_regularization': 1.67173145423823}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  22%|██▏       | 22/100 [00:41<02:18,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:24,119] Trial 21 finished with value: 0.7114411883753958 and parameters: {'learning_rate': 0.15606235943857025, 'max_leaf_nodes': 161, 'max_depth': 3, 'min_samples_leaf': 36, 'l2_regularization': 1.1538983477793558}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  23%|██▎       | 23/100 [00:42<01:58,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:25,088] Trial 22 finished with value: 0.7116244083152793 and parameters: {'learning_rate': 0.16567939757554387, 'max_leaf_nodes': 113, 'max_depth': 3, 'min_samples_leaf': 38, 'l2_regularization': 1.0578824535113296}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  24%|██▍       | 24/100 [00:43<01:57,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:26,669] Trial 23 finished with value: 0.7101719162991575 and parameters: {'learning_rate': 0.06453845960005232, 'max_leaf_nodes': 112, 'max_depth': 5, 'min_samples_leaf': 93, 'l2_regularization': 0.7825009551521904}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  25%|██▌       | 25/100 [00:44<01:46,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:27,804] Trial 24 finished with value: 0.7115548789398175 and parameters: {'learning_rate': 0.16810660615611409, 'max_leaf_nodes': 117, 'max_depth': 3, 'min_samples_leaf': 60, 'l2_regularization': 1.6091769660597557}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  26%|██▌       | 26/100 [00:45<01:35,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:28,763] Trial 25 finished with value: 0.7118167436301123 and parameters: {'learning_rate': 0.18211757993030314, 'max_leaf_nodes': 126, 'max_depth': 3, 'min_samples_leaf': 39, 'l2_regularization': 1.7481650941980054}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  27%|██▋       | 27/100 [00:46<01:33,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:30,026] Trial 26 finished with value: 0.6897688332416869 and parameters: {'learning_rate': 0.02693090140192227, 'max_leaf_nodes': 210, 'max_depth': 2, 'min_samples_leaf': 39, 'l2_regularization': 1.7693534276101113}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  28%|██▊       | 28/100 [00:48<01:33,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:31,391] Trial 27 finished with value: 0.7115765653425364 and parameters: {'learning_rate': 0.06835598916046864, 'max_leaf_nodes': 103, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 1.420334623084874}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  29%|██▉       | 29/100 [00:49<01:22,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:32,227] Trial 28 finished with value: 0.7105941821597398 and parameters: {'learning_rate': 0.20141062854092695, 'max_leaf_nodes': 162, 'max_depth': 4, 'min_samples_leaf': 90, 'l2_regularization': 1.8057429681665527}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  30%|███       | 30/100 [00:50<01:26,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:33,626] Trial 29 finished with value: 0.6543190705271632 and parameters: {'learning_rate': 0.006159763801939542, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 1.4244263182182964}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  31%|███       | 31/100 [00:52<01:36,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:35,416] Trial 30 finished with value: 0.7102961768070055 and parameters: {'learning_rate': 0.044633083858332666, 'max_leaf_nodes': 72, 'max_depth': 7, 'min_samples_leaf': 48, 'l2_regularization': 1.8438772085310369}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  32%|███▏      | 32/100 [00:53<01:34,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:36,799] Trial 31 finished with value: 0.7113445639695437 and parameters: {'learning_rate': 0.06839333098533881, 'max_leaf_nodes': 103, 'max_depth': 3, 'min_samples_leaf': 12, 'l2_regularization': 1.4968460061148146}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  33%|███▎      | 33/100 [00:54<01:26,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:37,859] Trial 32 finished with value: 0.7117003864375524 and parameters: {'learning_rate': 0.1373719848655973, 'max_leaf_nodes': 98, 'max_depth': 3, 'min_samples_leaf': 24, 'l2_regularization': 1.1405908268238405}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  34%|███▍      | 34/100 [00:55<01:12,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:38,517] Trial 33 finished with value: 0.7109372277085642 and parameters: {'learning_rate': 0.29570162630410596, 'max_leaf_nodes': 33, 'max_depth': 3, 'min_samples_leaf': 41, 'l2_regularization': 1.1153848998104845}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  35%|███▌      | 35/100 [00:56<01:07,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:39,415] Trial 34 finished with value: 0.7099483195562033 and parameters: {'learning_rate': 0.14943535441443334, 'max_leaf_nodes': 129, 'max_depth': 4, 'min_samples_leaf': 27, 'l2_regularization': 1.0449580807027812}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  36%|███▌      | 36/100 [00:57<01:08,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:40,568] Trial 35 finished with value: 0.7117252340608614 and parameters: {'learning_rate': 0.18961038846012815, 'max_leaf_nodes': 80, 'max_depth': 2, 'min_samples_leaf': 46, 'l2_regularization': 1.3345432032026956}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  37%|███▋      | 37/100 [00:58<01:08,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:41,683] Trial 36 finished with value: 0.7106594247999432 and parameters: {'learning_rate': 0.22242502941651002, 'max_leaf_nodes': 75, 'max_depth': 2, 'min_samples_leaf': 63, 'l2_regularization': 1.3043875972435837}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  38%|███▊      | 38/100 [00:59<01:10,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:42,912] Trial 37 finished with value: 0.7094344943059524 and parameters: {'learning_rate': 0.13094159937626157, 'max_leaf_nodes': 18, 'max_depth': 2, 'min_samples_leaf': 83, 'l2_regularization': 1.5342193682955556}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  39%|███▉      | 39/100 [01:01<01:14,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:44,359] Trial 38 finished with value: 0.7102815004118647 and parameters: {'learning_rate': 0.0821714230113661, 'max_leaf_nodes': 50, 'max_depth': 7, 'min_samples_leaf': 102, 'l2_regularization': 1.281106226489623}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  40%|████      | 40/100 [01:03<01:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:46,813] Trial 39 finished with value: 0.7092146251540972 and parameters: {'learning_rate': 0.02210485253094478, 'max_leaf_nodes': 82, 'max_depth': 8, 'min_samples_leaf': 48, 'l2_regularization': 0.8972662423848784}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  41%|████      | 41/100 [01:04<01:27,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:48,055] Trial 40 finished with value: 0.7016655144618748 and parameters: {'learning_rate': 0.043961082402741554, 'max_leaf_nodes': 94, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.7300599075169354}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  42%|████▏     | 42/100 [01:05<01:14,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:48,884] Trial 41 finished with value: 0.7114947058923569 and parameters: {'learning_rate': 0.19230223170419397, 'max_leaf_nodes': 102, 'max_depth': 3, 'min_samples_leaf': 42, 'l2_regularization': 1.89629571304215}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  43%|████▎     | 43/100 [01:06<01:10,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:50,024] Trial 42 finished with value: 0.7097399116418257 and parameters: {'learning_rate': 0.12155848822033463, 'max_leaf_nodes': 62, 'max_depth': 4, 'min_samples_leaf': 69, 'l2_regularization': 1.0036723461547976}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  44%|████▍     | 44/100 [01:08<01:09,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:51,256] Trial 43 finished with value: 0.7089683773199663 and parameters: {'learning_rate': 0.08681949183226238, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 55, 'l2_regularization': 0.8004955724585505}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  45%|████▌     | 45/100 [01:09<01:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:52,091] Trial 44 finished with value: 0.7095009389279976 and parameters: {'learning_rate': 0.2277240578109211, 'max_leaf_nodes': 156, 'max_depth': 3, 'min_samples_leaf': 31, 'l2_regularization': 1.208751135372487}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  46%|████▌     | 46/100 [01:09<00:53,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:52,808] Trial 45 finished with value: 0.7114079528822833 and parameters: {'learning_rate': 0.17560907532759612, 'max_leaf_nodes': 82, 'max_depth': 4, 'min_samples_leaf': 23, 'l2_regularization': 1.963076593426804}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.711841:  47%|████▋     | 47/100 [01:11<00:59,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:54,203] Trial 46 finished with value: 0.6078961685517081 and parameters: {'learning_rate': 0.0015036820177875864, 'max_leaf_nodes': 133, 'max_depth': 2, 'min_samples_leaf': 133, 'l2_regularization': 0.7067162227224034}. Best is trial 16 with value: 0.7118406276851876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  48%|████▊     | 48/100 [01:12<01:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:55,635] Trial 47 finished with value: 0.7125542109400096 and parameters: {'learning_rate': 0.10820205368450901, 'max_leaf_nodes': 151, 'max_depth': 4, 'min_samples_leaf': 171, 'l2_regularization': 1.053320649879196}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  49%|████▉     | 49/100 [01:14<01:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:57,181] Trial 48 finished with value: 0.711014642525352 and parameters: {'learning_rate': 0.11037236036763956, 'max_leaf_nodes': 170, 'max_depth': 4, 'min_samples_leaf': 194, 'l2_regularization': 1.5659287254470555}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  50%|█████     | 50/100 [01:14<00:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:57,849] Trial 49 finished with value: 0.7105210461171134 and parameters: {'learning_rate': 0.24322276725687914, 'max_leaf_nodes': 146, 'max_depth': 5, 'min_samples_leaf': 175, 'l2_regularization': 1.3536484585155149}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  51%|█████     | 51/100 [01:16<01:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:09:59,377] Trial 50 finished with value: 0.7080857958764969 and parameters: {'learning_rate': 0.052524328221481155, 'max_leaf_nodes': 211, 'max_depth': 4, 'min_samples_leaf': 146, 'l2_regularization': 0.43370917950992716}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  52%|█████▏    | 52/100 [01:17<01:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:00,707] Trial 51 finished with value: 0.7097599737579707 and parameters: {'learning_rate': 0.08949207952091896, 'max_leaf_nodes': 150, 'max_depth': 3, 'min_samples_leaf': 173, 'l2_regularization': 1.0555419953251253}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  53%|█████▎    | 53/100 [01:18<00:59,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:01,947] Trial 52 finished with value: 0.7114396970548397 and parameters: {'learning_rate': 0.13638571434187474, 'max_leaf_nodes': 107, 'max_depth': 3, 'min_samples_leaf': 121, 'l2_regularization': 1.0037828410067946}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  54%|█████▍    | 54/100 [01:20<00:58,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:03,222] Trial 53 finished with value: 0.7119158428424193 and parameters: {'learning_rate': 0.16306272070216865, 'max_leaf_nodes': 95, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 0.22220908011289486}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  55%|█████▌    | 55/100 [01:21<00:57,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:04,560] Trial 54 finished with value: 0.6228343382029395 and parameters: {'learning_rate': 0.003422259365356024, 'max_leaf_nodes': 255, 'max_depth': 2, 'min_samples_leaf': 54, 'l2_regularization': 0.9308936729793779}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  56%|█████▌    | 56/100 [01:22<00:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:05,184] Trial 55 finished with value: 0.7098383060313312 and parameters: {'learning_rate': 0.2805885119446281, 'max_leaf_nodes': 98, 'max_depth': 4, 'min_samples_leaf': 77, 'l2_regularization': 1.2086743967426936}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  57%|█████▋    | 57/100 [01:23<00:49,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:06,461] Trial 56 finished with value: 0.7116980777286777 and parameters: {'learning_rate': 0.10594100528996504, 'max_leaf_nodes': 171, 'max_depth': 3, 'min_samples_leaf': 44, 'l2_regularization': 0.1361779520593017}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  58%|█████▊    | 58/100 [01:24<00:48,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:07,647] Trial 57 finished with value: 0.7115466446169793 and parameters: {'learning_rate': 0.1891271010604147, 'max_leaf_nodes': 196, 'max_depth': 2, 'min_samples_leaf': 158, 'l2_regularization': 0.16831138147049124}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  59%|█████▉    | 59/100 [01:26<00:52,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:09,202] Trial 58 finished with value: 0.7103683712648479 and parameters: {'learning_rate': 0.08387250844710917, 'max_leaf_nodes': 71, 'max_depth': 5, 'min_samples_leaf': 105, 'l2_regularization': 1.7175079256241443}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  60%|██████    | 60/100 [01:27<00:50,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:10,417] Trial 59 finished with value: 0.7111354245644643 and parameters: {'learning_rate': 0.1414321894930817, 'max_leaf_nodes': 86, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 0.22703947415391923}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 47. Best value: 0.712554:  61%|██████    | 61/100 [01:27<00:39,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:10,890] Trial 60 finished with value: 0.7107077315982682 and parameters: {'learning_rate': 0.23519859090704748, 'max_leaf_nodes': 133, 'max_depth': 6, 'min_samples_leaf': 33, 'l2_regularization': 1.9061266846895542}. Best is trial 47 with value: 0.7125542109400096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: 0.712698:  62%|██████▏   | 62/100 [01:29<00:42,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:12,225] Trial 61 finished with value: 0.7126982544939015 and parameters: {'learning_rate': 0.10830961014719487, 'max_leaf_nodes': 173, 'max_depth': 3, 'min_samples_leaf': 45, 'l2_regularization': 0.12839847856588607}. Best is trial 61 with value: 0.7126982544939015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  63%|██████▎   | 63/100 [01:30<00:41,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:13,368] Trial 62 finished with value: 0.7129946573264214 and parameters: {'learning_rate': 0.11743916027856942, 'max_leaf_nodes': 200, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 0.3284057403455949}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  64%|██████▍   | 64/100 [01:31<00:46,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:15,007] Trial 63 finished with value: 0.7091573359859007 and parameters: {'learning_rate': 0.03439106631219419, 'max_leaf_nodes': 197, 'max_depth': 4, 'min_samples_leaf': 15, 'l2_regularization': 0.3169017612034969}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  65%|██████▌   | 65/100 [01:33<00:45,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:16,397] Trial 64 finished with value: 0.7117981815270307 and parameters: {'learning_rate': 0.10374939913158333, 'max_leaf_nodes': 175, 'max_depth': 3, 'min_samples_leaf': 57, 'l2_regularization': 0.238765934953317}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  66%|██████▌   | 66/100 [01:34<00:45,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:17,835] Trial 65 finished with value: 0.7094145189868895 and parameters: {'learning_rate': 0.06665361182314582, 'max_leaf_nodes': 229, 'max_depth': 3, 'min_samples_leaf': 54, 'l2_regularization': 0.23623242185802026}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  67%|██████▋   | 67/100 [01:36<00:44,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:19,177] Trial 66 finished with value: 0.711724478512291 and parameters: {'learning_rate': 0.10166339772790743, 'max_leaf_nodes': 182, 'max_depth': 3, 'min_samples_leaf': 68, 'l2_regularization': 0.44073376472470416}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  68%|██████▊   | 68/100 [01:37<00:44,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:20,709] Trial 67 finished with value: 0.711369949689139 and parameters: {'learning_rate': 0.057738564004010624, 'max_leaf_nodes': 173, 'max_depth': 4, 'min_samples_leaf': 39, 'l2_regularization': 0.5279168116899086}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  69%|██████▉   | 69/100 [01:39<00:43,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:22,135] Trial 68 finished with value: 0.7103343310809542 and parameters: {'learning_rate': 0.07726076243889807, 'max_leaf_nodes': 163, 'max_depth': 3, 'min_samples_leaf': 59, 'l2_regularization': 0.06688035982060758}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  70%|███████   | 70/100 [01:40<00:39,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:23,195] Trial 69 finished with value: 0.7115501026376078 and parameters: {'learning_rate': 0.11883401019020946, 'max_leaf_nodes': 191, 'max_depth': 4, 'min_samples_leaf': 87, 'l2_regularization': 0.2803130200294253}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  71%|███████   | 71/100 [01:41<00:38,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:24,576] Trial 70 finished with value: 0.7099255790572718 and parameters: {'learning_rate': 0.09247516449251865, 'max_leaf_nodes': 152, 'max_depth': 3, 'min_samples_leaf': 199, 'l2_regularization': 0.35822851253569254}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  72%|███████▏  | 72/100 [01:42<00:35,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:25,725] Trial 71 finished with value: 0.7119006771094133 and parameters: {'learning_rate': 0.1656469604204807, 'max_leaf_nodes': 203, 'max_depth': 2, 'min_samples_leaf': 47, 'l2_regularization': 0.15084534373724398}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  73%|███████▎  | 73/100 [01:43<00:33,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:26,886] Trial 72 finished with value: 0.7126486105591545 and parameters: {'learning_rate': 0.16087492915890325, 'max_leaf_nodes': 229, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.23439055030011707}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  74%|███████▍  | 74/100 [01:44<00:31,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:28,072] Trial 73 finished with value: 0.7123274284505771 and parameters: {'learning_rate': 0.16474490480199686, 'max_leaf_nodes': 225, 'max_depth': 2, 'min_samples_leaf': 34, 'l2_regularization': 0.1189146463512348}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  75%|███████▌  | 75/100 [01:46<00:30,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:29,335] Trial 74 finished with value: 0.7123237022862285 and parameters: {'learning_rate': 0.16435588771617557, 'max_leaf_nodes': 236, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.12613691279794173}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  76%|███████▌  | 76/100 [01:47<00:29,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:30,481] Trial 75 finished with value: 0.7124338396025555 and parameters: {'learning_rate': 0.16123063330678258, 'max_leaf_nodes': 236, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.118218675551796}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  77%|███████▋  | 77/100 [01:48<00:27,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:31,638] Trial 76 finished with value: 0.7120548826980807 and parameters: {'learning_rate': 0.16033769822460026, 'max_leaf_nodes': 238, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.10277458167088498}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  78%|███████▊  | 78/100 [01:49<00:25,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:32,643] Trial 77 finished with value: 0.7117795939682385 and parameters: {'learning_rate': 0.2646848909136091, 'max_leaf_nodes': 237, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.10681685536126403}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  79%|███████▉  | 79/100 [01:51<00:26,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:34,125] Trial 78 finished with value: 0.7121697127959938 and parameters: {'learning_rate': 0.12156293464153935, 'max_leaf_nodes': 225, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.011201269545078663}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  80%|████████  | 80/100 [01:52<00:24,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:35,385] Trial 79 finished with value: 0.7118535781013371 and parameters: {'learning_rate': 0.12701425571236372, 'max_leaf_nodes': 223, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.019209041012622025}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.712995:  81%|████████  | 81/100 [01:53<00:23,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:36,649] Trial 80 finished with value: 0.7119762919750093 and parameters: {'learning_rate': 0.21798444119265736, 'max_leaf_nodes': 245, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.17728578293104985}. Best is trial 62 with value: 0.7129946573264214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  82%|████████▏ | 82/100 [01:54<00:22,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:37,950] Trial 81 finished with value: 0.7130376601313593 and parameters: {'learning_rate': 0.1446629032904095, 'max_leaf_nodes': 238, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.0772550482459147}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  83%|████████▎ | 83/100 [01:56<00:21,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:39,216] Trial 82 finished with value: 0.711634800617986 and parameters: {'learning_rate': 0.1191948560132175, 'max_leaf_nodes': 226, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.05452568617570249}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  84%|████████▍ | 84/100 [01:57<00:20,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:40,484] Trial 83 finished with value: 0.7088021553537777 and parameters: {'learning_rate': 0.07717776612883974, 'max_leaf_nodes': 216, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.2822745122828334}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  85%|████████▌ | 85/100 [01:58<00:18,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:41,738] Trial 84 finished with value: 0.7126564830444475 and parameters: {'learning_rate': 0.1445590604115683, 'max_leaf_nodes': 237, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.007587965985295306}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  86%|████████▌ | 86/100 [01:59<00:17,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:42,972] Trial 85 finished with value: 0.7128149139467588 and parameters: {'learning_rate': 0.15063260762289069, 'max_leaf_nodes': 235, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.09897146907133589}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  87%|████████▋ | 87/100 [02:01<00:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:44,363] Trial 86 finished with value: 0.6719962852987917 and parameters: {'learning_rate': 0.011993015790736663, 'max_leaf_nodes': 244, 'max_depth': 2, 'min_samples_leaf': 34, 'l2_regularization': 0.1787820882372495}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  88%|████████▊ | 88/100 [02:02<00:15,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:45,631] Trial 87 finished with value: 0.7124917017388015 and parameters: {'learning_rate': 0.2124264493052109, 'max_leaf_nodes': 253, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 0.407693494178307}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  89%|████████▉ | 89/100 [02:03<00:13,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:46,766] Trial 88 finished with value: 0.7127701002282001 and parameters: {'learning_rate': 0.21031006643215155, 'max_leaf_nodes': 255, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.372525681630386}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  90%|█████████ | 90/100 [02:04<00:10,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:47,255] Trial 89 finished with value: 0.7101848972825145 and parameters: {'learning_rate': 0.2165747895875878, 'max_leaf_nodes': 256, 'max_depth': 10, 'min_samples_leaf': 25, 'l2_regularization': 0.3921087146696228}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.713038:  91%|█████████ | 91/100 [02:05<00:09,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:48,459] Trial 90 finished with value: 0.7123719231482197 and parameters: {'learning_rate': 0.2561046891156773, 'max_leaf_nodes': 249, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.6360028261975669}. Best is trial 81 with value: 0.7130376601313593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.713448:  92%|█████████▏| 92/100 [02:06<00:08,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:49,694] Trial 91 finished with value: 0.7134484052651783 and parameters: {'learning_rate': 0.1905219886805287, 'max_leaf_nodes': 231, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.3324455083185729}. Best is trial 91 with value: 0.7134484052651783.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.713448:  93%|█████████▎| 93/100 [02:07<00:08,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:50,943] Trial 92 finished with value: 0.7127434941232227 and parameters: {'learning_rate': 0.19139301632290354, 'max_leaf_nodes': 244, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.3418018035318217}. Best is trial 91 with value: 0.7134484052651783.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.713448:  94%|█████████▍| 94/100 [02:08<00:06,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:52,005] Trial 93 finished with value: 0.7123651556197238 and parameters: {'learning_rate': 0.29836912638196744, 'max_leaf_nodes': 243, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.32913259853667626}. Best is trial 91 with value: 0.7134484052651783.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496:  95%|█████████▌| 95/100 [02:10<00:05,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:53,288] Trial 94 finished with value: 0.7134956683669356 and parameters: {'learning_rate': 0.1436980465592784, 'max_leaf_nodes': 230, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.497736995221496}. Best is trial 94 with value: 0.7134956683669356.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496:  96%|█████████▌| 96/100 [02:11<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:54,567] Trial 95 finished with value: 0.7118902476750971 and parameters: {'learning_rate': 0.1918989122286827, 'max_leaf_nodes': 232, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.4814708327032577}. Best is trial 94 with value: 0.7134956683669356.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496:  97%|█████████▋| 97/100 [02:12<00:03,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:55,166] Trial 96 finished with value: 0.7103295353738093 and parameters: {'learning_rate': 0.14788295322940317, 'max_leaf_nodes': 214, 'max_depth': 9, 'min_samples_leaf': 37, 'l2_regularization': 0.2758439755396107}. Best is trial 94 with value: 0.7134956683669356.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496:  98%|█████████▊| 98/100 [02:13<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:56,393] Trial 97 finished with value: 0.7121869948218456 and parameters: {'learning_rate': 0.13800585319777184, 'max_leaf_nodes': 205, 'max_depth': 2, 'min_samples_leaf': 31, 'l2_regularization': 0.5779825328351963}. Best is trial 94 with value: 0.7134956683669356.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496:  99%|█████████▉| 99/100 [02:14<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:57,536] Trial 98 finished with value: 0.7125133447231466 and parameters: {'learning_rate': 0.18640707212536722, 'max_leaf_nodes': 249, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.35089598832989344}. Best is trial 94 with value: 0.7134956683669356.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 94. Best value: 0.713496: 100%|██████████| 100/100 [02:15<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 18:10:58,538] Trial 99 finished with value: 0.712574211041901 and parameters: {'learning_rate': 0.25424352863560434, 'max_leaf_nodes': 219, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.19473415623571627}. Best is trial 94 with value: 0.7134956683669356.\n",
      "Optuna optimization completed in 00:02:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=random_seed))\n",
    "start = time.time()\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Optuna optimization completed in {format_hms(end - start)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>l2_regularization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.713496</td>\n",
       "      <td>0.143698</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.497737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.713448</td>\n",
       "      <td>0.190522</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.332446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.713038</td>\n",
       "      <td>0.144663</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.077255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.712995</td>\n",
       "      <td>0.117439</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.328406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.712815</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>235</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0.098971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  learning_rate  max_leaf_nodes  max_depth  min_samples_leaf  \\\n",
       "94  0.713496       0.143698             230          2                23   \n",
       "91  0.713448       0.190522             231          2                24   \n",
       "81  0.713038       0.144663             238          2                19   \n",
       "62  0.712995       0.117439             200          3                19   \n",
       "85  0.712815       0.150633             235          2                33   \n",
       "\n",
       "    l2_regularization  \n",
       "94           0.497737  \n",
       "91           0.332446  \n",
       "81           0.077255  \n",
       "62           0.328406  \n",
       "85           0.098971  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert study results to a DataFrame\n",
    "optuna_results = pd.DataFrame([\n",
    "    {\n",
    "        \"f1_score\": trial.value,\n",
    "        **trial.params\n",
    "    }\n",
    "    for trial in study.trials\n",
    "])\n",
    "\n",
    "# Sort and show top 5\n",
    "top5_optuna = optuna_results.sort_values(by=\"f1_score\", ascending=False).head(5)\n",
    "display(top5_optuna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 (Best F1 Score from Optuna): 0.7135\n"
     ]
    }
   ],
   "source": [
    "print(f\"a3 (Best F1 Score from Optuna): {study.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Graded Answer\n",
    "\n",
    "Set `a3` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a3 = study.best_value                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 = 0.7135\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a3 = {a3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Final Model Evaluation on Test Set\n",
    "\n",
    "In this problem, you will take the best hyperparameter configuration you found in your earlier experiments (Randomized Search or Optuna) and fully evaluate the resulting model on the test set.\n",
    "\n",
    "**Background:**\n",
    "When performing hyperparameter tuning, we typically optimize for a single metric (e.g., F1). However, before deployment, it is essential to check **all relevant metrics** on the final test set to understand the model’s behavior in a balanced way.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Take the best hyperparameters you found in Problems 2 or 3 and apply them to your `pipelined_model`.\n",
    "2. Re-train this final tuned model on the **entire training set** (not just the folds).\n",
    "3. Evaluate the final model on the heldout **test set**, reporting the following metrics:\n",
    "\n",
    "   * Precision\n",
    "   * Recall\n",
    "   * F1 score\n",
    "   * Balanced accuracy\n",
    "4. Use `classification_report` **on the test set** to print precision, recall, and F1 score, and use `balanced_accuracy_score` separately to calculate and print balanced accuracy.\n",
    "5. Answer the graded questions.\n",
    "\n",
    "**Note:** We evaluate the metrics on the test set because it was never seen during training or hyperparameter tuning. This gives us an unbiased estimate of how the model will perform on truly unseen data. Evaluating on the training set would be misleading, because the model has already learned from that data and could appear artificially good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9537    0.8225    0.8832      7431\n",
      "           1     0.6074    0.8730    0.7164      2338\n",
      "\n",
      "    accuracy                         0.8346      9769\n",
      "   macro avg     0.7805    0.8477    0.7998      9769\n",
      "weighted avg     0.8708    0.8346    0.8433      9769\n",
      "\n",
      "Balanced Accuracy (a4a):      0.8477\n",
      "Macro Avg Precision (a4b):    0.7805\n",
      "Macro Avg Recall (a4c):       0.8477\n"
     ]
    }
   ],
   "source": [
    "clean_params = {k.replace(\"gb__\", \"\"): v for k, v in random_search.best_params_.items()}\n",
    "\n",
    "final_model = HistGradientBoostingClassifier(\n",
    "    **clean_params,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\", final_model)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "\n",
    "print(f\"Balanced Accuracy (a4a):      {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Macro Avg Precision (a4b):    {report_dict[\"macro avg\"][\"precision\"]:.4f}\")\n",
    "print(f\"Macro Avg Recall (a4c):       {report_dict[\"macro avg\"][\"recall\"]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Graded Questions\n",
    "\n",
    "- Set `a4a` to the balanced accuracy score of the best model.\n",
    "- Set `a4b` to the macro average precision of this model.\n",
    "- Set `a4c` to the macro average recall score of the this model.\n",
    "\n",
    "**Note:** Macro average takes the mean of each class’s precision/recall without considering how many samples each class has, which is appropriate for a balanced evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4a = balanced_accuracy_score(y_test, y_pred)                     # replace 0 with your answer, use variable or expression from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = 0.8477\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4a = {a4a:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4b = report_dict[\"macro avg\"][\"precision\"]                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = 0.7805\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4b = {a4b:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4c = report_dict[\"macro avg\"][\"recall\"]                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4c = 0.8477\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4c = {a4c:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Understanding Precision, Recall, F1, and Balanced Accuracy\n",
    "\n",
    "**Tutorial**\n",
    "\n",
    "In binary classification, you will often evaluate these key metrics:\n",
    "\n",
    "* **Precision**: *Of all the positive predictions the model made, how many were actually correct?*\n",
    "\n",
    "  * High precision = few false positives\n",
    "  * Low precision = many false positives\n",
    "\n",
    "* **Recall**: *Of all the actual positive cases, how many did the model correctly identify?*\n",
    "\n",
    "  * High recall = few false negatives\n",
    "  * Low recall = many false negatives\n",
    "\n",
    "* **F1 score**: The harmonic mean of precision and recall, which balances them in a single measure.\n",
    "\n",
    "  * F1 is **highest** when precision and recall are both high and similar in value.\n",
    "  * If precision and recall are unbalanced, F1 will drop to reflect that imbalance.\n",
    "\n",
    "* **Balanced accuracy**: The average of recall across both classes (positive and negative).\n",
    "\n",
    "  * It ensures the classifier is performing reasonably well on *both* groups, correcting for class imbalance.\n",
    "  * Balanced accuracy is especially important if the classes are very unequal in size.\n",
    "\n",
    "**Typical trade-offs to remember:**\n",
    "\n",
    "* **Higher recall, lower precision**: the model finds most true positives but also mislabels some negatives as positives\n",
    "* **Higher precision, lower recall**: the model is strict about positive predictions, but misses some true positives\n",
    "* **Balanced precision and recall (good F1)**: a practical compromise\n",
    "* **Balanced accuracy**: checks fairness across both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 5 Graded Question (multiple choice)\n",
    "\n",
    "A bank uses your model to identify customers earning over $50K for a premium product invitation. Based on your final test set evaluation, including macro-averaged precision and recall, which of the following best describes what might happen?\n",
    "\n",
    "(1) The bank will miss some eligible high-income customers, but will avoid marketing mistakes by sending invitations only to those it is  confident about.\n",
    "\n",
    "(2) The bank will successfully reach most high-income customers, but will also waste resources sending invitations to some low-income customers.\n",
    "\n",
    "(3) The bank will perfectly identify all high-income and low-income customers, resulting in no wasted invitations and no missed opportunities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a5 = 2                     # replace 0 with one of 1, 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5 = 2\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a5 = {a5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix One: Feature Engineering\n",
    "\n",
    "Here are some practical feature-engineering tweaks worth considering (beyond simply ordinal-encoding the categoricals)\n",
    "\n",
    "| Feature(s)                                                           | Why the tweak can help                                                                                                                                                     | How to do it (quick version)                                                                                                                                                    | Keep / drop?      |\n",
    "| -------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- |\n",
    "| **`fnlwgt`**                                                         | Survey sampling weight, not a predictor. Leaving it in often lets the model “cheat.”                                                                                       | `df = df.drop(columns=[\"fnlwgt\"])`                                                                                                                                              | **Drop**          |\n",
    "| **`education` *vs.* `education-num`**                                | They encode the **same** information twice (categorical label and its ordinal rank). Keeping both is redundant and can cause leakage of a perfectly predictive feature.    | Usually keep **only one**. For tree models `education-num` is simplest: `df = df.drop(columns=[\"education\"])`                                                                   | **Drop one**      |\n",
    "| **`capital-gain`, `capital-loss`**                                   | Highly skewed; most values are zero with a long upper tail. The sign (gain vs. loss) matters, but treating them separately wastes a feature slot.                          | 1) Combine: `df[\"capital_net\"] = df[\"capital-gain\"] - df[\"capital-loss\"]`; 2) Log-transform to reduce skew: `df[\"capital_net_log\"] = np.log1p(df[\"capital_net\"].clip(lower=0))` | Replace originals |\n",
    "| **`age`, `hours-per-week`**                                          | Continuous but with natural plateaus—trees handle splits fine, yet log or square-root scaling can soften extreme values; bucketing makes partial-dependence plots clearer. | Simple bucket: `df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[16,25,35,45,55,65,90])` (optional)                                                                                      | Optional          |\n",
    "| **Missing categories** (`workclass`, `occupation`, `native-country`) | HGB handles `-1`/`-2` codes fine, but you may want *explicit* “Missing” bucket for interpretability.                                                                       | Use `encoded_missing_value=-2` during encoding.                                                                                                            | Keep as is        |\n",
    "| **Rare categories in `native-country`**                              | Hundreds of low-frequency countries dilute signal; grouping boosts stability.                                                                                              | Map infrequent categories to “Other”:                                                                                                                                           |                   |\n",
    "\n",
    "\n",
    "#### Minimum set of tweaks (good baseline, low effort)\n",
    "\n",
    "1. **Drop `fnlwgt`.**  \n",
    "2. **Keep `education-num`, drop `education`.**  \n",
    "3. **Combine `capital-gain` and `capital-loss` into `capital_net`** (optionally add a log-scaled version).  \n",
    "4. Leave other numeric/categorical features as is; your histogram-GBDT will cope.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
